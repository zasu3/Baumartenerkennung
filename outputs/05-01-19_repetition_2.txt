duser@8395372068e0:~$ python repetition.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 100
learnrate: 0.1
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2019-01-05 22:42:19.950795: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-05 22:42:20.405468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.74GiB
2019-01-05 22:42:20.774989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 22:42:21.186977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 22:42:21.557372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 22:42:21.557461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-05 22:42:22.498838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-05 22:42:22.498882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-05 22:42:22.498894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-05 22:42:22.498902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-05 22:42:22.498910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-05 22:42:22.498918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-05 22:42:22.501214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29820 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-05 22:42:22.501636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-05 22:42:22.501963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-05 22:42:22.502259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
468/467 [==============================] - 45s 96ms/step - loss: 14.0320 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 2/10
468/467 [==============================] - 38s 82ms/step - loss: 14.0563 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 3/10
468/467 [==============================] - 40s 85ms/step - loss: 14.0553 - acc: 0.1280 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 4/10
468/467 [==============================] - 38s 81ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 5/10
468/467 [==============================] - 39s 84ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 6/10
468/467 [==============================] - 38s 81ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 7/10
468/467 [==============================] - 38s 80ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 8/10
468/467 [==============================] - 37s 79ms/step - loss: 14.0579 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 9/10
468/467 [==============================] - 39s 83ms/step - loss: 14.0579 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 10/10
468/467 [==============================] - 38s 81ms/step - loss: 14.0548 - acc: 0.1280 - val_loss: 14.6675 - val_acc: 0.0900
Test loss: 14.667520550191503
Test accuracy: 0.08999665440943537
2019-01-05 22:48:54.806833
on validation data
11956/11956 [==============================] - 5s 405us/step
accuaracy 8.999665440943536
Total loss 1466.7520550191502
batchsize: 200
learnrate: 0.1
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 47s 201ms/step - loss: 14.0117 - acc: 0.1273 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 2/10
234/233 [==============================] - 45s 193ms/step - loss: 14.0573 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 3/10
234/233 [==============================] - 44s 188ms/step - loss: 14.0579 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 4/10
234/233 [==============================] - 42s 178ms/step - loss: 14.0564 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 5/10
234/233 [==============================] - 44s 187ms/step - loss: 14.0570 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 6/10
234/233 [==============================] - 45s 190ms/step - loss: 14.0580 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 7/10
234/233 [==============================] - 43s 182ms/step - loss: 14.0570 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 8/10
234/233 [==============================] - 37s 157ms/step - loss: 14.0577 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 9/10
234/233 [==============================] - 40s 170ms/step - loss: 14.0580 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 10/10
234/233 [==============================] - 43s 182ms/step - loss: 14.0577 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Test loss: 14.667520550191503
Test accuracy: 0.08999665440943537
2019-01-05 22:56:58.156177
on validation data
11956/11956 [==============================] - 5s 428us/step
accuaracy 8.999665440943536
Total loss 1466.7520550191502
batchsize: 250
learnrate: 0.1
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 50s 268ms/step - loss: 13.2049 - acc: 0.1767 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 40s 212ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 38s 205ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 37s 200ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 42s 227ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 43s 231ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 44s 235ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 41s 220ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-05 23:04:53.320994
on validation data
11956/11956 [==============================] - 5s 426us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 64
learnrate: 0.0001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 38s 53ms/step - loss: 1.8755 - acc: 0.3264 - val_loss: 2.3213 - val_acc: 0.2635
Epoch 2/10
731/730 [==============================] - 36s 49ms/step - loss: 1.5744 - acc: 0.4463 - val_loss: 2.1994 - val_acc: 0.3180
Epoch 3/10
731/730 [==============================] - 36s 49ms/step - loss: 1.3329 - acc: 0.5353 - val_loss: 2.2271 - val_acc: 0.3295
Epoch 4/10
731/730 [==============================] - 36s 49ms/step - loss: 1.1567 - acc: 0.6001 - val_loss: 2.3531 - val_acc: 0.3504
Epoch 5/10
731/730 [==============================] - 36s 50ms/step - loss: 1.0063 - acc: 0.6542 - val_loss: 2.3252 - val_acc: 0.3547
Epoch 6/10
731/730 [==============================] - 36s 50ms/step - loss: 0.8845 - acc: 0.6971 - val_loss: 2.2710 - val_acc: 0.3924
Epoch 7/10
731/730 [==============================] - 36s 50ms/step - loss: 0.7642 - acc: 0.7396 - val_loss: 2.4717 - val_acc: 0.3835
Epoch 8/10
731/730 [==============================] - 36s 50ms/step - loss: 0.6739 - acc: 0.7689 - val_loss: 2.5392 - val_acc: 0.4093
Epoch 9/10
731/730 [==============================] - 36s 49ms/step - loss: 0.5866 - acc: 0.7988 - val_loss: 2.6439 - val_acc: 0.3827
Epoch 10/10
731/730 [==============================] - 36s 50ms/step - loss: 0.5044 - acc: 0.8249 - val_loss: 2.6244 - val_acc: 0.3917
Test loss: 2.624364452323773
Test accuracy: 0.3916861826498479
2019-01-05 23:11:51.799314
on validation data
11956/11956 [==============================] - 4s 359us/step
accuaracy 39.16861826498479
Total loss 262.4364452323773
batchsize: 100
learnrate: 0.0001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_10 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_15 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 38s 82ms/step - loss: 1.9171 - acc: 0.3129 - val_loss: 2.3532 - val_acc: 0.2616
Epoch 2/10
468/467 [==============================] - 38s 82ms/step - loss: 1.6422 - acc: 0.4240 - val_loss: 2.1315 - val_acc: 0.3282
Epoch 3/10
468/467 [==============================] - 38s 81ms/step - loss: 1.4319 - acc: 0.5038 - val_loss: 2.3197 - val_acc: 0.3044
Epoch 4/10
468/467 [==============================] - 36s 77ms/step - loss: 1.2631 - acc: 0.5605 - val_loss: 2.1854 - val_acc: 0.3273
Epoch 5/10
468/467 [==============================] - 36s 77ms/step - loss: 1.1261 - acc: 0.6107 - val_loss: 2.1910 - val_acc: 0.3729
Epoch 6/10
468/467 [==============================] - 37s 80ms/step - loss: 1.0073 - acc: 0.6557 - val_loss: 2.2935 - val_acc: 0.3753
Epoch 7/10
468/467 [==============================] - 39s 84ms/step - loss: 0.8806 - acc: 0.6983 - val_loss: 2.4523 - val_acc: 0.3775
Epoch 8/10
468/467 [==============================] - 38s 80ms/step - loss: 0.7995 - acc: 0.7265 - val_loss: 2.3408 - val_acc: 0.4020
Epoch 9/10
468/467 [==============================] - 38s 82ms/step - loss: 0.7078 - acc: 0.7572 - val_loss: 2.5112 - val_acc: 0.3783
Epoch 10/10
468/467 [==============================] - 39s 84ms/step - loss: 0.6235 - acc: 0.7856 - val_loss: 2.5577 - val_acc: 0.3981
Test loss: 2.557706366577608
Test accuracy: 0.3981264637102049
2019-01-05 23:19:02.820123
on validation data
11956/11956 [==============================] - 4s 363us/step
accuaracy 39.81264637102049
Total loss 255.77063665776078
batchsize: 200
learnrate: 0.0001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_12 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_18 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 47s 203ms/step - loss: 1.9482 - acc: 0.3014 - val_loss: 2.3114 - val_acc: 0.2551
Epoch 2/10
234/233 [==============================] - 42s 181ms/step - loss: 1.6818 - acc: 0.4054 - val_loss: 2.2355 - val_acc: 0.3210
Epoch 3/10
234/233 [==============================] - 43s 184ms/step - loss: 1.5087 - acc: 0.4730 - val_loss: 2.2284 - val_acc: 0.3192
Epoch 4/10
234/233 [==============================] - 45s 193ms/step - loss: 1.3532 - acc: 0.5267 - val_loss: 2.2654 - val_acc: 0.3420
Epoch 5/10
234/233 [==============================] - 44s 187ms/step - loss: 1.2298 - acc: 0.5704 - val_loss: 2.3369 - val_acc: 0.3300
Epoch 6/10
234/233 [==============================] - 42s 179ms/step - loss: 1.1213 - acc: 0.6111 - val_loss: 2.2076 - val_acc: 0.3551
Epoch 7/10
234/233 [==============================] - 38s 164ms/step - loss: 1.0318 - acc: 0.6437 - val_loss: 2.4384 - val_acc: 0.3305
Epoch 8/10
234/233 [==============================] - 42s 180ms/step - loss: 0.9540 - acc: 0.6710 - val_loss: 2.3072 - val_acc: 0.3847
Epoch 9/10
234/233 [==============================] - 44s 189ms/step - loss: 0.8855 - acc: 0.6968 - val_loss: 2.4300 - val_acc: 0.3865
Epoch 10/10
234/233 [==============================] - 37s 159ms/step - loss: 0.8232 - acc: 0.7169 - val_loss: 2.3670 - val_acc: 0.3936
Test loss: 2.3670363275452018
Test accuracy: 0.39360990297758447
2019-01-05 23:27:03.455393
on validation data
11956/11956 [==============================] - 5s 435us/step
accuaracy 39.36099029775845
Total loss 236.70363275452019
batchsize: 250
learnrate: 0.0001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_14 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_20 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_21 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 42s 225ms/step - loss: 1.9617 - acc: 0.3000 - val_loss: 2.3677 - val_acc: 0.2201
Epoch 2/10
187/186 [==============================] - 39s 209ms/step - loss: 1.7001 - acc: 0.4019 - val_loss: 2.2795 - val_acc: 0.3061
Epoch 3/10
187/186 [==============================] - 44s 235ms/step - loss: 1.5408 - acc: 0.4591 - val_loss: 2.2189 - val_acc: 0.3107
Epoch 4/10
187/186 [==============================] - 36s 195ms/step - loss: 1.4141 - acc: 0.5059 - val_loss: 2.3100 - val_acc: 0.3172
Epoch 5/10
187/186 [==============================] - 40s 211ms/step - loss: 1.3054 - acc: 0.5431 - val_loss: 2.3188 - val_acc: 0.3218
Epoch 6/10
187/186 [==============================] - 43s 232ms/step - loss: 1.1824 - acc: 0.5879 - val_loss: 2.2808 - val_acc: 0.3847
Epoch 7/10
187/186 [==============================] - 39s 209ms/step - loss: 1.1063 - acc: 0.6165 - val_loss: 2.2516 - val_acc: 0.3493
Epoch 8/10
187/186 [==============================] - 43s 231ms/step - loss: 1.0335 - acc: 0.6427 - val_loss: 2.2643 - val_acc: 0.3778
Epoch 9/10
187/186 [==============================] - 42s 226ms/step - loss: 0.9574 - acc: 0.6711 - val_loss: 2.3458 - val_acc: 0.3877
Epoch 10/10
187/186 [==============================] - 43s 231ms/step - loss: 0.8786 - acc: 0.6967 - val_loss: 2.4399 - val_acc: 0.3770
Test loss: 2.4398657966114756
Test accuracy: 0.3769655403244571
2019-01-05 23:34:48.898646
on validation data
11956/11956 [==============================] - 4s 359us/step
accuaracy 37.69655403244571
Total loss 243.98657966114757
batchsize: 64
learnrate: 0.001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_22 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_16 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_23 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_24 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 37s 51ms/step - loss: 1.9893 - acc: 0.2889 - val_loss: 2.2670 - val_acc: 0.2415
Epoch 2/10
731/730 [==============================] - 36s 49ms/step - loss: 1.7491 - acc: 0.3801 - val_loss: 2.2447 - val_acc: 0.2606
Epoch 3/10
731/730 [==============================] - 36s 49ms/step - loss: 1.6613 - acc: 0.4167 - val_loss: 2.2550 - val_acc: 0.3089
Epoch 4/10
731/730 [==============================] - 36s 49ms/step - loss: 1.5534 - acc: 0.4548 - val_loss: 2.4010 - val_acc: 0.3099
Epoch 5/10
731/730 [==============================] - 36s 49ms/step - loss: 1.4826 - acc: 0.4844 - val_loss: 2.2559 - val_acc: 0.3172
Epoch 6/10
731/730 [==============================] - 36s 50ms/step - loss: 1.4245 - acc: 0.5014 - val_loss: 2.1768 - val_acc: 0.3489
Epoch 7/10
731/730 [==============================] - 36s 49ms/step - loss: 1.3968 - acc: 0.5169 - val_loss: 2.2478 - val_acc: 0.3283
Epoch 8/10
731/730 [==============================] - 36s 49ms/step - loss: 1.3448 - acc: 0.5321 - val_loss: 2.2846 - val_acc: 0.3203
Epoch 9/10
731/730 [==============================] - 36s 50ms/step - loss: 1.3149 - acc: 0.5419 - val_loss: 2.4043 - val_acc: 0.3335
Epoch 10/10
731/730 [==============================] - 36s 50ms/step - loss: 1.2761 - acc: 0.5562 - val_loss: 2.2374 - val_acc: 0.3500
Test loss: 2.237370914900809
Test accuracy: 0.35003345600535296
2019-01-05 23:41:42.317834
on validation data
11956/11956 [==============================] - 4s 365us/step
accuaracy 35.0033456005353
Total loss 223.73709149008093
batchsize: 100
learnrate: 0.001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_43 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_25 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_18 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_26 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_27 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 40s 87ms/step - loss: 2.0174 - acc: 0.2774 - val_loss: 2.3229 - val_acc: 0.1898
Epoch 2/10
468/467 [==============================] - 37s 78ms/step - loss: 1.8282 - acc: 0.3458 - val_loss: 2.3669 - val_acc: 0.2738
Epoch 3/10
468/467 [==============================] - 37s 78ms/step - loss: 1.6860 - acc: 0.4087 - val_loss: 2.2487 - val_acc: 0.2784
Epoch 4/10
468/467 [==============================] - 38s 81ms/step - loss: 1.6118 - acc: 0.4287 - val_loss: 2.4124 - val_acc: 0.2919
Epoch 5/10
468/467 [==============================] - 36s 77ms/step - loss: 1.5367 - acc: 0.4575 - val_loss: 2.2068 - val_acc: 0.3039
Epoch 6/10
468/467 [==============================] - 38s 82ms/step - loss: 1.4699 - acc: 0.4833 - val_loss: 2.2347 - val_acc: 0.3183
Epoch 7/10
468/467 [==============================] - 39s 83ms/step - loss: 1.4107 - acc: 0.5065 - val_loss: 2.2242 - val_acc: 0.3156
Epoch 8/10
468/467 [==============================] - 41s 87ms/step - loss: 1.3635 - acc: 0.5223 - val_loss: 2.3106 - val_acc: 0.3244
Epoch 9/10
468/467 [==============================] - 40s 85ms/step - loss: 1.3109 - acc: 0.5400 - val_loss: 2.3630 - val_acc: 0.3174
Epoch 10/10
468/467 [==============================] - 40s 86ms/step - loss: 1.2786 - acc: 0.5541 - val_loss: 2.3141 - val_acc: 0.3266
Test loss: 2.3140740893923266
Test accuracy: 0.3266142522782217
2019-01-05 23:49:03.178325
on validation data
11956/11956 [==============================] - 4s 358us/step
accuaracy 32.66142522782217
Total loss 231.40740893923265
batchsize: 200
learnrate: 0.001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_47 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_49 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_28 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_20 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_29 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_30 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 43s 183ms/step - loss: 2.0587 - acc: 0.2749 - val_loss: 2.4159 - val_acc: 0.1772
Epoch 2/10
234/233 [==============================] - 45s 190ms/step - loss: 1.8145 - acc: 0.3532 - val_loss: 2.3530 - val_acc: 0.2620
Epoch 3/10
234/233 [==============================] - 41s 174ms/step - loss: 1.6893 - acc: 0.4031 - val_loss: 2.1498 - val_acc: 0.2943
Epoch 4/10
234/233 [==============================] - 41s 175ms/step - loss: 1.5813 - acc: 0.4438 - val_loss: 2.2048 - val_acc: 0.3164
Epoch 5/10
234/233 [==============================] - 43s 183ms/step - loss: 1.5367 - acc: 0.4602 - val_loss: 2.2193 - val_acc: 0.3080
Epoch 6/10
234/233 [==============================] - 44s 186ms/step - loss: 1.4330 - acc: 0.4975 - val_loss: 2.2868 - val_acc: 0.3023
Epoch 7/10
234/233 [==============================] - 44s 189ms/step - loss: 1.3978 - acc: 0.5118 - val_loss: 2.2308 - val_acc: 0.3518
Epoch 8/10
234/233 [==============================] - 44s 189ms/step - loss: 1.3373 - acc: 0.5309 - val_loss: 2.2241 - val_acc: 0.3396
Epoch 9/10
234/233 [==============================] - 45s 193ms/step - loss: 1.2855 - acc: 0.5494 - val_loss: 2.3502 - val_acc: 0.3284
Epoch 10/10
234/233 [==============================] - 41s 175ms/step - loss: 1.2571 - acc: 0.5585 - val_loss: 2.3037 - val_acc: 0.3478
Test loss: 2.3037055272567866
Test accuracy: 0.3477751756639694
2019-01-05 23:57:05.349883
on validation data
11956/11956 [==============================] - 4s 364us/step
accuaracy 34.777517566396945
Total loss 230.37055272567866
batchsize: 250
learnrate: 0.001
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_53 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_55 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_31 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_22 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_32 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_33 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 47s 252ms/step - loss: 2.0787 - acc: 0.2573 - val_loss: 2.3846 - val_acc: 0.1740
Epoch 2/10
187/186 [==============================] - 41s 222ms/step - loss: 1.8184 - acc: 0.3478 - val_loss: 2.2562 - val_acc: 0.2759
Epoch 3/10
187/186 [==============================] - 43s 232ms/step - loss: 1.6640 - acc: 0.4173 - val_loss: 2.2162 - val_acc: 0.2727
Epoch 4/10
187/186 [==============================] - 45s 240ms/step - loss: 1.5630 - acc: 0.4567 - val_loss: 2.2013 - val_acc: 0.3248
Epoch 5/10
187/186 [==============================] - 43s 231ms/step - loss: 1.4856 - acc: 0.4848 - val_loss: 2.0635 - val_acc: 0.3481
Epoch 6/10
187/186 [==============================] - 40s 214ms/step - loss: 1.3939 - acc: 0.5200 - val_loss: 2.2892 - val_acc: 0.3508
Epoch 7/10
187/186 [==============================] - 43s 232ms/step - loss: 1.3309 - acc: 0.5398 - val_loss: 2.3334 - val_acc: 0.3382
Epoch 8/10
187/186 [==============================] - 44s 234ms/step - loss: 1.2543 - acc: 0.5661 - val_loss: 2.2171 - val_acc: 0.3464
Epoch 9/10
187/186 [==============================] - 45s 239ms/step - loss: 1.1874 - acc: 0.5899 - val_loss: 2.2770 - val_acc: 0.3495
Epoch 10/10
187/186 [==============================] - 45s 240ms/step - loss: 1.1435 - acc: 0.6091 - val_loss: 2.2912 - val_acc: 0.3370
Test loss: 2.291236467926189
Test accuracy: 0.3369856139276689
2019-01-06 00:05:17.563038
on validation data
11956/11956 [==============================] - 4s 376us/step
accuaracy 33.69856139276689
Total loss 229.1236467926189
batchsize: 64
learnrate: 0.01
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_57 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_59 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_60 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_34 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_24 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_35 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_36 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 39s 53ms/step - loss: 13.2449 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
731/730 [==============================] - 38s 52ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
731/730 [==============================] - 36s 50ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2603 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2603 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
731/730 [==============================] - 33s 46ms/step - loss: 13.2588 - acc: 0.1774 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 00:12:17.226222
on validation data
11956/11956 [==============================] - 5s 406us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 100
learnrate: 0.01
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_63 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_64 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_65 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_37 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_26 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_38 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_39 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 42s 90ms/step - loss: 13.5596 - acc: 0.1572 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 2/10
468/467 [==============================] - 38s 82ms/step - loss: 13.5831 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 3/10
468/467 [==============================] - 42s 90ms/step - loss: 13.5821 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 4/10
468/467 [==============================] - 39s 83ms/step - loss: 13.5800 - acc: 0.1575 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 5/10
468/467 [==============================] - 41s 88ms/step - loss: 13.5816 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 6/10
468/467 [==============================] - 40s 85ms/step - loss: 13.5836 - acc: 0.1572 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 7/10
468/467 [==============================] - 42s 90ms/step - loss: 13.5816 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 8/10
468/467 [==============================] - 38s 81ms/step - loss: 13.5826 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 9/10
468/467 [==============================] - 38s 81ms/step - loss: 13.5810 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 10/10
468/467 [==============================] - 39s 84ms/step - loss: 13.5816 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Test loss: 14.764584989921032
Test accuracy: 0.08397457343717808
2019-01-06 00:19:50.250041
on validation data
11956/11956 [==============================] - 4s 375us/step
accuaracy 8.397457343717809
Total loss 1476.4584989921032
batchsize: 200
learnrate: 0.01
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_67 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_68 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_69 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_40 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_28 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_41 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_42 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Traceback (most recent call last):
  File "repetition.py", line 364, in <module>
    run(200, 0.01, 96, 3)
  File "repetition.py", line 258, in run
    datagen_train.fit(X_train)
  File "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py", line 1363, in fit
    x = np.copy(x)
  File "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py", line 733, in copy
    return array(a, order=order, copy=True)
MemoryError