duser@8395372068e0:~$ python repetition_best.py
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 64
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
2019-01-06 11:48:21.140587: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-06 11:48:21.542268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.74GiB
2019-01-06 11:48:21.922693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 11:48:22.302232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 11:48:22.670749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 11:48:22.670837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-06 11:48:23.629940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-06 11:48:23.629984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-06 11:48:23.629997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-06 11:48:23.630007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-06 11:48:23.630016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-06 11:48:23.630024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-06 11:48:23.632250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29820 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-06 11:48:23.632673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-06 11:48:23.633003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-06 11:48:23.633305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
731/730 [==============================] - 44s 61ms/step - loss: 1.9204 - acc: 0.3083 - val_loss: 2.3486 - val_acc: 0.2655
Epoch 2/20
731/730 [==============================] - 37s 50ms/step - loss: 1.6561 - acc: 0.4173 - val_loss: 2.2955 - val_acc: 0.2628
Epoch 3/20
731/730 [==============================] - 36s 50ms/step - loss: 1.4346 - acc: 0.5004 - val_loss: 2.2960 - val_acc: 0.3263
Epoch 4/20
731/730 [==============================] - 36s 49ms/step - loss: 1.2644 - acc: 0.5632 - val_loss: 2.1278 - val_acc: 0.3561
Epoch 5/20
731/730 [==============================] - 36s 49ms/step - loss: 1.1263 - acc: 0.6110 - val_loss: 2.3168 - val_acc: 0.3492
Epoch 6/20
731/730 [==============================] - 37s 50ms/step - loss: 0.9943 - acc: 0.6608 - val_loss: 2.3296 - val_acc: 0.3491
Epoch 7/20
731/730 [==============================] - 36s 50ms/step - loss: 0.8802 - acc: 0.6976 - val_loss: 2.4083 - val_acc: 0.3731
Epoch 8/20
731/730 [==============================] - 37s 50ms/step - loss: 0.7771 - acc: 0.7355 - val_loss: 2.4360 - val_acc: 0.4109
Epoch 9/20
731/730 [==============================] - 36s 49ms/step - loss: 0.6847 - acc: 0.7647 - val_loss: 2.3928 - val_acc: 0.4290
Epoch 10/20
731/730 [==============================] - 36s 50ms/step - loss: 0.5869 - acc: 0.7963 - val_loss: 2.5242 - val_acc: 0.4258
Epoch 11/20
731/730 [==============================] - 36s 49ms/step - loss: 0.5389 - acc: 0.8144 - val_loss: 2.5437 - val_acc: 0.4384
Epoch 12/20
731/730 [==============================] - 36s 49ms/step - loss: 0.4669 - acc: 0.8378 - val_loss: 2.7932 - val_acc: 0.4170
Epoch 13/20
731/730 [==============================] - 37s 50ms/step - loss: 0.4101 - acc: 0.8579 - val_loss: 2.7096 - val_acc: 0.4363
Epoch 14/20
731/730 [==============================] - 36s 50ms/step - loss: 0.3627 - acc: 0.8739 - val_loss: 2.9509 - val_acc: 0.4209
Epoch 15/20
731/730 [==============================] - 35s 48ms/step - loss: 0.3294 - acc: 0.8845 - val_loss: 2.9389 - val_acc: 0.4433
Epoch 16/20
731/730 [==============================] - 36s 49ms/step - loss: 0.2796 - acc: 0.9039 - val_loss: 2.9371 - val_acc: 0.4321
Epoch 17/20
731/730 [==============================] - 36s 50ms/step - loss: 0.2730 - acc: 0.9035 - val_loss: 3.2795 - val_acc: 0.4312
Epoch 18/20
731/730 [==============================] - 36s 50ms/step - loss: 0.2325 - acc: 0.9189 - val_loss: 3.5270 - val_acc: 0.4016
Epoch 19/20
731/730 [==============================] - 37s 50ms/step - loss: 0.2193 - acc: 0.9232 - val_loss: 2.9895 - val_acc: 0.4513
Epoch 20/20
731/730 [==============================] - 36s 49ms/step - loss: 0.2065 - acc: 0.9279 - val_loss: 3.7732 - val_acc: 0.4278
Test loss: 3.7732087767375435
Test accuracy: 0.4278186684509869
2019-01-06 12:00:39.219200
on validation data
11956/11956 [==============================] - 5s 394us/step
accuaracy 42.78186684509869
Total loss 377.32087767375435
batchsize: 100
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
468/467 [==============================] - 36s 76ms/step - loss: 1.9363 - acc: 0.3011 - val_loss: 2.3352 - val_acc: 0.1988
Epoch 2/20
468/467 [==============================] - 37s 79ms/step - loss: 1.6635 - acc: 0.4115 - val_loss: 2.3346 - val_acc: 0.2801
Epoch 3/20
468/467 [==============================] - 38s 82ms/step - loss: 1.4733 - acc: 0.4824 - val_loss: 2.2052 - val_acc: 0.3264
Epoch 4/20
468/467 [==============================] - 37s 80ms/step - loss: 1.3167 - acc: 0.5421 - val_loss: 2.1915 - val_acc: 0.3509
Epoch 5/20
468/467 [==============================] - 38s 82ms/step - loss: 1.1687 - acc: 0.5954 - val_loss: 2.3317 - val_acc: 0.3310
Epoch 6/20
468/467 [==============================] - 37s 78ms/step - loss: 1.0516 - acc: 0.6373 - val_loss: 2.3551 - val_acc: 0.3447
Epoch 7/20
468/467 [==============================] - 38s 82ms/step - loss: 0.9384 - acc: 0.6783 - val_loss: 2.4297 - val_acc: 0.3687
Epoch 8/20
468/467 [==============================] - 38s 81ms/step - loss: 0.8355 - acc: 0.7125 - val_loss: 2.5194 - val_acc: 0.3863
Epoch 9/20
468/467 [==============================] - 38s 82ms/step - loss: 0.7415 - acc: 0.7461 - val_loss: 2.3763 - val_acc: 0.3983
Epoch 10/20
468/467 [==============================] - 38s 82ms/step - loss: 0.6721 - acc: 0.7681 - val_loss: 2.3870 - val_acc: 0.4185
Epoch 11/20
468/467 [==============================] - 38s 81ms/step - loss: 0.5813 - acc: 0.7985 - val_loss: 2.6914 - val_acc: 0.4034
Epoch 12/20
468/467 [==============================] - 37s 80ms/step - loss: 0.5226 - acc: 0.8186 - val_loss: 2.5737 - val_acc: 0.4317
Epoch 13/20
468/467 [==============================] - 38s 82ms/step - loss: 0.4589 - acc: 0.8392 - val_loss: 2.7339 - val_acc: 0.4297
Epoch 14/20
468/467 [==============================] - 38s 82ms/step - loss: 0.4172 - acc: 0.8543 - val_loss: 2.7457 - val_acc: 0.4260
Epoch 15/20
468/467 [==============================] - 36s 78ms/step - loss: 0.3759 - acc: 0.8689 - val_loss: 3.1351 - val_acc: 0.4060
Epoch 16/20
468/467 [==============================] - 36s 77ms/step - loss: 0.3419 - acc: 0.8804 - val_loss: 3.1348 - val_acc: 0.4246
Epoch 17/20
468/467 [==============================] - 40s 86ms/step - loss: 0.3044 - acc: 0.8936 - val_loss: 3.3244 - val_acc: 0.4103
Epoch 18/20
468/467 [==============================] - 38s 81ms/step - loss: 0.2666 - acc: 0.9071 - val_loss: 3.2482 - val_acc: 0.4305
Epoch 19/20
468/467 [==============================] - 37s 78ms/step - loss: 0.2508 - acc: 0.9118 - val_loss: 3.3118 - val_acc: 0.4487
Epoch 20/20
468/467 [==============================] - 37s 79ms/step - loss: 0.2254 - acc: 0.9193 - val_loss: 3.6455 - val_acc: 0.4224
Test loss: 3.6454833546144263
Test accuracy: 0.42238206756118946
2019-01-06 12:14:05.980212
on validation data
11956/11956 [==============================] - 5s 403us/step
accuaracy 42.23820675611895
Total loss 364.5483354614426
batchsize: 200
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
234/233 [==============================] - 51s 216ms/step - loss: 1.9622 - acc: 0.2936 - val_loss: 2.3049 - val_acc: 0.2158
Epoch 2/20
234/233 [==============================] - 45s 191ms/step - loss: 1.7136 - acc: 0.3912 - val_loss: 2.1426 - val_acc: 0.3167
Epoch 3/20
234/233 [==============================] - 45s 194ms/step - loss: 1.5515 - acc: 0.4557 - val_loss: 2.1948 - val_acc: 0.3275
Epoch 4/20
234/233 [==============================] - 39s 168ms/step - loss: 1.3876 - acc: 0.5158 - val_loss: 2.3760 - val_acc: 0.3372
Epoch 5/20
234/233 [==============================] - 44s 187ms/step - loss: 1.2671 - acc: 0.5574 - val_loss: 2.2078 - val_acc: 0.3530
Epoch 6/20
234/233 [==============================] - 44s 190ms/step - loss: 1.1598 - acc: 0.5997 - val_loss: 2.2557 - val_acc: 0.3565
Epoch 7/20
234/233 [==============================] - 45s 192ms/step - loss: 1.0653 - acc: 0.6328 - val_loss: 2.3339 - val_acc: 0.3563
Epoch 8/20
234/233 [==============================] - 46s 195ms/step - loss: 0.9697 - acc: 0.6683 - val_loss: 2.1768 - val_acc: 0.3841
Epoch 9/20
234/233 [==============================] - 45s 194ms/step - loss: 0.8845 - acc: 0.6949 - val_loss: 2.3448 - val_acc: 0.3877
Epoch 10/20
234/233 [==============================] - 46s 196ms/step - loss: 0.8028 - acc: 0.7245 - val_loss: 2.4790 - val_acc: 0.3966
Epoch 11/20
234/233 [==============================] - 40s 173ms/step - loss: 0.7382 - acc: 0.7479 - val_loss: 2.3670 - val_acc: 0.4050
Epoch 12/20
234/233 [==============================] - 39s 169ms/step - loss: 0.6705 - acc: 0.7675 - val_loss: 2.4512 - val_acc: 0.4093
Epoch 13/20
234/233 [==============================] - 42s 180ms/step - loss: 0.6207 - acc: 0.7854 - val_loss: 2.5454 - val_acc: 0.4273
Epoch 14/20
234/233 [==============================] - 36s 152ms/step - loss: 0.5618 - acc: 0.8062 - val_loss: 2.5118 - val_acc: 0.4385
Epoch 15/20
234/233 [==============================] - 45s 192ms/step - loss: 0.5086 - acc: 0.8228 - val_loss: 2.7445 - val_acc: 0.4077
Epoch 16/20
234/233 [==============================] - 40s 170ms/step - loss: 0.4704 - acc: 0.8349 - val_loss: 2.7051 - val_acc: 0.4361
Epoch 17/20
234/233 [==============================] - 43s 183ms/step - loss: 0.4198 - acc: 0.8538 - val_loss: 2.6577 - val_acc: 0.4512
Epoch 18/20
234/233 [==============================] - 39s 165ms/step - loss: 0.4008 - acc: 0.8611 - val_loss: 2.8137 - val_acc: 0.4487
Epoch 19/20
234/233 [==============================] - 41s 175ms/step - loss: 0.3497 - acc: 0.8773 - val_loss: 2.8055 - val_acc: 0.4349
Epoch 20/20
234/233 [==============================] - 45s 191ms/step - loss: 0.3317 - acc: 0.8830 - val_loss: 2.8332 - val_acc: 0.4398
Test loss: 2.8331634881864147
Test accuracy: 0.43977919036467045
2019-01-06 12:29:18.784596
on validation data
11956/11956 [==============================] - 5s 399us/step
accuaracy 43.97791903646704
Total loss 283.3163488186415
batchsize: 250
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
187/186 [==============================] - 49s 264ms/step - loss: 2.0000 - acc: 0.2843 - val_loss: 2.3692 - val_acc: 0.1930
Epoch 2/20
187/186 [==============================] - 43s 231ms/step - loss: 1.7528 - acc: 0.3769 - val_loss: 2.2871 - val_acc: 0.2717
Epoch 3/20
187/186 [==============================] - 38s 202ms/step - loss: 1.6103 - acc: 0.4322 - val_loss: 2.1408 - val_acc: 0.3395
Epoch 4/20
187/186 [==============================] - 43s 230ms/step - loss: 1.4667 - acc: 0.4863 - val_loss: 2.2905 - val_acc: 0.3177
Epoch 5/20
187/186 [==============================] - 44s 233ms/step - loss: 1.3392 - acc: 0.5300 - val_loss: 2.1719 - val_acc: 0.3362
Epoch 6/20
187/186 [==============================] - 43s 231ms/step - loss: 1.2039 - acc: 0.5790 - val_loss: 2.3442 - val_acc: 0.3398
Epoch 7/20
187/186 [==============================] - 44s 235ms/step - loss: 1.1018 - acc: 0.6200 - val_loss: 2.1580 - val_acc: 0.3830
Epoch 8/20
187/186 [==============================] - 43s 229ms/step - loss: 1.0255 - acc: 0.6461 - val_loss: 2.1822 - val_acc: 0.3839
Epoch 9/20
187/186 [==============================] - 44s 233ms/step - loss: 0.9272 - acc: 0.6849 - val_loss: 2.1914 - val_acc: 0.4100
Epoch 10/20
187/186 [==============================] - 40s 216ms/step - loss: 0.8369 - acc: 0.7164 - val_loss: 2.2377 - val_acc: 0.4108
Epoch 11/20
187/186 [==============================] - 42s 223ms/step - loss: 0.7877 - acc: 0.7288 - val_loss: 2.3732 - val_acc: 0.4083
Epoch 12/20
187/186 [==============================] - 40s 216ms/step - loss: 0.7179 - acc: 0.7539 - val_loss: 2.3534 - val_acc: 0.4011
Epoch 13/20
187/186 [==============================] - 41s 220ms/step - loss: 0.6487 - acc: 0.7753 - val_loss: 2.3763 - val_acc: 0.4168
Epoch 14/20
187/186 [==============================] - 40s 216ms/step - loss: 0.6128 - acc: 0.7873 - val_loss: 2.5136 - val_acc: 0.4113
Epoch 15/20
187/186 [==============================] - 41s 220ms/step - loss: 0.5491 - acc: 0.8085 - val_loss: 2.4262 - val_acc: 0.4456
Epoch 16/20
187/186 [==============================] - 39s 206ms/step - loss: 0.5117 - acc: 0.8221 - val_loss: 2.3762 - val_acc: 0.4372
Epoch 17/20
187/186 [==============================] - 37s 196ms/step - loss: 0.4617 - acc: 0.8383 - val_loss: 2.5385 - val_acc: 0.4550
Epoch 18/20
187/186 [==============================] - 42s 224ms/step - loss: 0.4215 - acc: 0.8525 - val_loss: 2.9028 - val_acc: 0.4205
Epoch 19/20
187/186 [==============================] - 43s 233ms/step - loss: 0.3825 - acc: 0.8660 - val_loss: 2.7289 - val_acc: 0.4324
Epoch 20/20
187/186 [==============================] - 42s 223ms/step - loss: 0.3505 - acc: 0.8772 - val_loss: 2.7870 - val_acc: 0.4532
Test loss: 2.7870006325173913
Test accuracy: 0.4531615925058548
2019-01-06 12:44:12.090260
on validation data
11956/11956 [==============================] - 5s 377us/step
accuaracy 45.31615925058548
Total loss 278.70006325173915
batchsize: 64
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_10 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_15 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
731/730 [==============================] - 38s 51ms/step - loss: 1.8968 - acc: 0.3188 - val_loss: 2.2904 - val_acc: 0.2494
Epoch 2/20
731/730 [==============================] - 36s 49ms/step - loss: 1.5948 - acc: 0.4367 - val_loss: 2.2876 - val_acc: 0.2939
Epoch 3/20
731/730 [==============================] - 37s 50ms/step - loss: 1.3333 - acc: 0.5354 - val_loss: 2.2324 - val_acc: 0.3332
Epoch 4/20
731/730 [==============================] - 36s 50ms/step - loss: 1.1368 - acc: 0.6069 - val_loss: 2.2965 - val_acc: 0.3548
Epoch 5/20
731/730 [==============================] - 37s 50ms/step - loss: 0.9954 - acc: 0.6588 - val_loss: 2.2674 - val_acc: 0.3808
Epoch 6/20
731/730 [==============================] - 36s 50ms/step - loss: 0.8497 - acc: 0.7108 - val_loss: 2.3179 - val_acc: 0.4123
Epoch 7/20
731/730 [==============================] - 36s 49ms/step - loss: 0.7290 - acc: 0.7514 - val_loss: 2.6594 - val_acc: 0.4058
Epoch 8/20
731/730 [==============================] - 37s 50ms/step - loss: 0.6286 - acc: 0.7836 - val_loss: 2.4367 - val_acc: 0.4310
Epoch 9/20
731/730 [==============================] - 36s 49ms/step - loss: 0.5503 - acc: 0.8106 - val_loss: 2.4106 - val_acc: 0.4484
Epoch 10/20
731/730 [==============================] - 37s 50ms/step - loss: 0.4767 - acc: 0.8357 - val_loss: 2.6127 - val_acc: 0.4577
Epoch 11/20
731/730 [==============================] - 37s 50ms/step - loss: 0.4141 - acc: 0.8578 - val_loss: 2.5814 - val_acc: 0.4700
Epoch 12/20
731/730 [==============================] - 36s 50ms/step - loss: 0.3563 - acc: 0.8759 - val_loss: 2.9116 - val_acc: 0.4429
Epoch 13/20
731/730 [==============================] - 36s 50ms/step - loss: 0.3277 - acc: 0.8866 - val_loss: 2.9809 - val_acc: 0.4426
Epoch 14/20
731/730 [==============================] - 36s 50ms/step - loss: 0.2878 - acc: 0.9018 - val_loss: 2.9179 - val_acc: 0.4665
Epoch 15/20
731/730 [==============================] - 37s 50ms/step - loss: 0.2493 - acc: 0.9123 - val_loss: 3.1231 - val_acc: 0.4417
Epoch 16/20
731/730 [==============================] - 37s 50ms/step - loss: 0.2236 - acc: 0.9216 - val_loss: 3.5924 - val_acc: 0.4368
Epoch 17/20
731/730 [==============================] - 36s 50ms/step - loss: 0.2125 - acc: 0.9259 - val_loss: 3.5664 - val_acc: 0.4435
Epoch 18/20
731/730 [==============================] - 36s 50ms/step - loss: 0.1849 - acc: 0.9348 - val_loss: 3.5263 - val_acc: 0.4630
Epoch 19/20
731/730 [==============================] - 36s 49ms/step - loss: 0.1732 - acc: 0.9397 - val_loss: 3.8069 - val_acc: 0.4358
Epoch 20/20
731/730 [==============================] - 36s 50ms/step - loss: 0.1600 - acc: 0.9445 - val_loss: 3.6585 - val_acc: 0.4526
Test loss: 3.658468268475193
Test accuracy: 0.45257611239223666
2019-01-06 12:57:13.936769
on validation data
11956/11956 [==============================] - 5s 415us/step
accuaracy 45.257611239223664
Total loss 365.84682684751925
batchsize: 100
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_12 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_18 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
468/467 [==============================] - 38s 81ms/step - loss: 1.9095 - acc: 0.3165 - val_loss: 2.3680 - val_acc: 0.2734
Epoch 2/20
468/467 [==============================] - 40s 85ms/step - loss: 1.6187 - acc: 0.4266 - val_loss: 2.2763 - val_acc: 0.3053
Epoch 3/20
468/467 [==============================] - 39s 83ms/step - loss: 1.3951 - acc: 0.5158 - val_loss: 2.2652 - val_acc: 0.3465
Epoch 4/20
468/467 [==============================] - 38s 82ms/step - loss: 1.2101 - acc: 0.5820 - val_loss: 2.2437 - val_acc: 0.3684
Epoch 5/20
468/467 [==============================] - 40s 85ms/step - loss: 1.0497 - acc: 0.6397 - val_loss: 2.3330 - val_acc: 0.3762
Epoch 6/20
468/467 [==============================] - 38s 81ms/step - loss: 0.9128 - acc: 0.6870 - val_loss: 2.4433 - val_acc: 0.3864
Epoch 7/20
468/467 [==============================] - 39s 84ms/step - loss: 0.7981 - acc: 0.7263 - val_loss: 2.3338 - val_acc: 0.4180
Epoch 8/20
468/467 [==============================] - 38s 82ms/step - loss: 0.6999 - acc: 0.7592 - val_loss: 2.5189 - val_acc: 0.4251
Epoch 9/20
468/467 [==============================] - 37s 78ms/step - loss: 0.6109 - acc: 0.7900 - val_loss: 2.5473 - val_acc: 0.4206
Epoch 10/20
468/467 [==============================] - 39s 84ms/step - loss: 0.5357 - acc: 0.8160 - val_loss: 2.6063 - val_acc: 0.4412
Epoch 11/20
468/467 [==============================] - 41s 87ms/step - loss: 0.4812 - acc: 0.8347 - val_loss: 2.5602 - val_acc: 0.4363
Epoch 12/20
468/467 [==============================] - 41s 88ms/step - loss: 0.4236 - acc: 0.8536 - val_loss: 2.7714 - val_acc: 0.4415
Epoch 13/20
468/467 [==============================] - 39s 82ms/step - loss: 0.3684 - acc: 0.8701 - val_loss: 2.8543 - val_acc: 0.4279
Epoch 14/20
468/467 [==============================] - 37s 79ms/step - loss: 0.3218 - acc: 0.8888 - val_loss: 2.9710 - val_acc: 0.4578
Epoch 15/20
468/467 [==============================] - 39s 84ms/step - loss: 0.2933 - acc: 0.8959 - val_loss: 2.8789 - val_acc: 0.4650
Epoch 16/20
468/467 [==============================] - 37s 80ms/step - loss: 0.2525 - acc: 0.9119 - val_loss: 3.0908 - val_acc: 0.4450
Epoch 17/20
468/467 [==============================] - 38s 81ms/step - loss: 0.2278 - acc: 0.9208 - val_loss: 3.2349 - val_acc: 0.4465
Epoch 18/20
468/467 [==============================] - 38s 80ms/step - loss: 0.2029 - acc: 0.9297 - val_loss: 3.2017 - val_acc: 0.4421
Epoch 19/20
468/467 [==============================] - 40s 85ms/step - loss: 0.1836 - acc: 0.9357 - val_loss: 3.5493 - val_acc: 0.4708
Epoch 20/20
468/467 [==============================] - 38s 82ms/step - loss: 0.1851 - acc: 0.9357 - val_loss: 3.8873 - val_acc: 0.4492
Test loss: 3.887273252349348
Test accuracy: 0.4492305118569406
2019-01-06 13:11:02.683102
on validation data
11956/11956 [==============================] - 5s 422us/step
accuaracy 44.92305118569406
Total loss 388.7273252349348
batchsize: 200
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_14 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_20 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_21 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/20
234/233 [==============================] - 45s 193ms/step - loss: 1.9456 - acc: 0.3017 - val_loss: 2.4308 - val_acc: 0.2125
Epoch 2/20
234/233 [==============================] - 42s 180ms/step - loss: 1.6805 - acc: 0.4013 - val_loss: 2.1953 - val_acc: 0.3208
Epoch 3/20
234/233 [==============================] - 42s 178ms/step - loss: 1.5090 - acc: 0.4741 - val_loss: 2.0879 - val_acc: 0.3454
Epoch 4/20
234/233 [==============================] - 43s 183ms/step - loss: 1.3592 - acc: 0.5270 - val_loss: 2.2305 - val_acc: 0.3538
Epoch 5/20
234/233 [==============================] - 44s 186ms/step - loss: 1.2123 - acc: 0.5796 - val_loss: 2.1651 - val_acc: 0.3614
Epoch 6/20
234/233 [==============================] - 31s 132ms/step - loss: 1.1026 - acc: 0.6183 - val_loss: 2.2508 - val_acc: 0.3775
Epoch 7/20
234/233 [==============================] - 31s 133ms/step - loss: 0.9935 - acc: 0.6569 - val_loss: 2.1173 - val_acc: 0.4144
Epoch 8/20
234/233 [==============================] - 43s 185ms/step - loss: 0.8898 - acc: 0.6956 - val_loss: 2.3012 - val_acc: 0.4221
Epoch 9/20
234/233 [==============================] - 45s 191ms/step - loss: 0.7951 - acc: 0.7275 - val_loss: 2.2960 - val_acc: 0.4103
Epoch 10/20
234/233 [==============================] - 45s 191ms/step - loss: 0.7268 - acc: 0.7503 - val_loss: 2.2996 - val_acc: 0.4300
Epoch 11/20
234/233 [==============================] - 42s 179ms/step - loss: 0.6673 - acc: 0.7697 - val_loss: 2.3334 - val_acc: 0.4266
Epoch 12/20
234/233 [==============================] - 43s 185ms/step - loss: 0.5938 - acc: 0.7960 - val_loss: 2.4218 - val_acc: 0.4119
Epoch 13/20
234/233 [==============================] - 45s 193ms/step - loss: 0.5455 - acc: 0.8114 - val_loss: 2.4979 - val_acc: 0.4324
Epoch 14/20
234/233 [==============================] - 45s 192ms/step - loss: 0.4982 - acc: 0.8270 - val_loss: 2.2794 - val_acc: 0.4578
Epoch 15/20
234/233 [==============================] - 43s 184ms/step - loss: 0.4446 - acc: 0.8462 - val_loss: 2.4284 - val_acc: 0.4669
Epoch 16/20
234/233 [==============================] - 44s 188ms/step - loss: 0.4119 - acc: 0.8581 - val_loss: 2.5416 - val_acc: 0.4753
Epoch 17/20
234/233 [==============================] - 44s 189ms/step - loss: 0.3547 - acc: 0.8771 - val_loss: 2.8272 - val_acc: 0.4548
Epoch 18/20
234/233 [==============================] - 43s 184ms/step - loss: 0.3300 - acc: 0.8857 - val_loss: 2.7333 - val_acc: 0.4729
Epoch 19/20
234/233 [==============================] - 44s 186ms/step - loss: 0.3014 - acc: 0.8954 - val_loss: 3.1341 - val_acc: 0.4472
Epoch 20/20
234/233 [==============================] - 41s 174ms/step - loss: 0.2798 - acc: 0.9024 - val_loss: 3.0487 - val_acc: 0.4548
Test loss: 3.0486982301869654
Test accuracy: 0.45475075275014976
2019-01-06 13:26:00.145710
on validation data
11956/11956 [==============================] - 5s 439us/step
accuaracy 45.47507527501497
Total loss 304.86982301869654