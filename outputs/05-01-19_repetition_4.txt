duser@8395372068e0:~$ python repetition.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 250
learnrate: 0.001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2019-01-06 10:31:46.174095: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-06 10:31:46.589316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.74GiB
2019-01-06 10:31:46.962239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 10:31:47.337516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 10:31:47.734814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 10:31:47.734910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-06 10:31:48.684086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-06 10:31:48.684128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-06 10:31:48.684141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-06 10:31:48.684150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-06 10:31:48.684162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-06 10:31:48.684174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-06 10:31:48.686510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29820 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-06 10:31:48.686955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-06 10:31:48.687304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-06 10:31:48.687622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
187/186 [==============================] - 51s 273ms/step - loss: 2.1221 - acc: 0.2527 - val_loss: 2.5061 - val_acc: 0.1677
Epoch 2/10
187/186 [==============================] - 42s 223ms/step - loss: 1.9108 - acc: 0.3135 - val_loss: 2.3574 - val_acc: 0.2032
Epoch 3/10
187/186 [==============================] - 44s 234ms/step - loss: 1.8248 - acc: 0.3493 - val_loss: 2.4042 - val_acc: 0.2228
Epoch 4/10
187/186 [==============================] - 42s 225ms/step - loss: 1.7537 - acc: 0.3761 - val_loss: 2.3988 - val_acc: 0.2205
Epoch 5/10
187/186 [==============================] - 43s 229ms/step - loss: 1.7049 - acc: 0.3972 - val_loss: 2.2983 - val_acc: 0.2466
Epoch 6/10
187/186 [==============================] - 40s 211ms/step - loss: 1.6496 - acc: 0.4176 - val_loss: 2.3661 - val_acc: 0.2640
Epoch 7/10
187/186 [==============================] - 41s 220ms/step - loss: 1.5893 - acc: 0.4378 - val_loss: 2.3134 - val_acc: 0.2809
Epoch 8/10
187/186 [==============================] - 42s 227ms/step - loss: 1.5474 - acc: 0.4530 - val_loss: 2.3246 - val_acc: 0.2681
Epoch 9/10
187/186 [==============================] - 41s 217ms/step - loss: 1.5066 - acc: 0.4673 - val_loss: 2.3661 - val_acc: 0.2734
Epoch 10/10
187/186 [==============================] - 43s 229ms/step - loss: 1.4610 - acc: 0.4852 - val_loss: 2.3075 - val_acc: 0.2915
Test loss: 2.307548614599586
Test accuracy: 0.29148544664764214
2019-01-06 10:38:59.140752
on validation data
11956/11956 [==============================] - 5s 397us/step
accuaracy 29.148544664764213
Total loss 230.7548614599586
batchsize: 64
learnrate: 0.01
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 39s 53ms/step - loss: 13.5669 - acc: 0.1572 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 13.5823 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 3/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5808 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 4/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5830 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 5/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5800 - acc: 0.1575 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 6/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5823 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 7/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5800 - acc: 0.1575 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 8/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5823 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 9/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5823 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 10/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5800 - acc: 0.1575 - val_loss: 14.7646 - val_acc: 0.0840
Test loss: 14.764584989921032
Test accuracy: 0.08397457343717808
2019-01-06 10:45:55.771649
on validation data
11956/11956 [==============================] - 4s 360us/step
accuaracy 8.397457343717809
Total loss 1476.4584989921032
batchsize: 100
learnrate: 0.01
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 39s 83ms/step - loss: 14.0353 - acc: 0.1275 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 2/10
468/467 [==============================] - 36s 77ms/step - loss: 14.0584 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 3/10
468/467 [==============================] - 37s 79ms/step - loss: 14.0558 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 4/10
468/467 [==============================] - 38s 80ms/step - loss: 14.0584 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 5/10
468/467 [==============================] - 41s 87ms/step - loss: 14.0568 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 6/10
468/467 [==============================] - 38s 82ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 7/10
468/467 [==============================] - 38s 82ms/step - loss: 14.0589 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 8/10
468/467 [==============================] - 39s 83ms/step - loss: 14.0568 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 9/10
468/467 [==============================] - 37s 80ms/step - loss: 14.0558 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 10/10
468/467 [==============================] - 37s 80ms/step - loss: 14.0568 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Test loss: 14.667520550191503
Test accuracy: 0.08999665440943537
2019-01-06 10:53:08.932933
on validation data
11956/11956 [==============================] - 5s 404us/step
accuaracy 8.999665440943536
Total loss 1466.7520550191502
batchsize: 200
learnrate: 0.01
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 49s 211ms/step - loss: 13.2145 - acc: 0.1768 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 40s 172ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 41s 176ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 44s 189ms/step - loss: 13.2606 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 44s 187ms/step - loss: 13.2621 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 43s 185ms/step - loss: 13.2621 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 44s 189ms/step - loss: 13.2611 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 42s 180ms/step - loss: 13.2606 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 45s 191ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 40s 171ms/step - loss: 13.2625 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 11:01:17.494069
on validation data
11956/11956 [==============================] - 5s 406us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 250
learnrate: 0.01
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_10 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_15 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 41s 221ms/step - loss: 14.0005 - acc: 0.1272 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 2/10
187/186 [==============================] - 43s 232ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 3/10
187/186 [==============================] - 44s 236ms/step - loss: 14.0572 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 4/10
187/186 [==============================] - 44s 236ms/step - loss: 14.0573 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 5/10
187/186 [==============================] - 45s 239ms/step - loss: 14.0574 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 6/10
187/186 [==============================] - 42s 224ms/step - loss: 14.0572 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 7/10
187/186 [==============================] - 42s 224ms/step - loss: 14.0576 - acc: 0.1278 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 8/10
187/186 [==============================] - 44s 235ms/step - loss: 14.0573 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 9/10
187/186 [==============================] - 43s 229ms/step - loss: 14.0573 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Epoch 10/10
187/186 [==============================] - 43s 233ms/step - loss: 14.0570 - acc: 0.1279 - val_loss: 14.6675 - val_acc: 0.0900
Test loss: 14.667520550191503
Test accuracy: 0.08999665440943537
2019-01-06 11:09:22.886572
on validation data
11956/11956 [==============================] - 4s 369us/step
accuaracy 8.999665440943536
Total loss 1466.7520550191502
batchsize: 64
learnrate: 0.1
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_12 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_18 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 38s 51ms/step - loss: 13.2437 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2588 - acc: 0.1774 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2641 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
731/730 [==============================] - 36s 50ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
731/730 [==============================] - 36s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2595 - acc: 0.1774 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 11:16:26.872852
on validation data
11956/11956 [==============================] - 4s 365us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 100
learnrate: 0.1
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_14 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_20 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_21 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 39s 84ms/step - loss: 13.2382 - acc: 0.1770 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
468/467 [==============================] - 37s 79ms/step - loss: 13.2599 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
468/467 [==============================] - 38s 80ms/step - loss: 13.2609 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
468/467 [==============================] - 39s 83ms/step - loss: 13.2625 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
468/467 [==============================] - 37s 79ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
468/467 [==============================] - 38s 81ms/step - loss: 13.2625 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
468/467 [==============================] - 39s 82ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
468/467 [==============================] - 40s 85ms/step - loss: 13.2609 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
468/467 [==============================] - 41s 87ms/step - loss: 13.2630 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
468/467 [==============================] - 39s 83ms/step - loss: 13.2609 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 11:23:44.520090
on validation data
11956/11956 [==============================] - 4s 362us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 200
learnrate: 0.1
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_22 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_16 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_23 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_24 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 44s 188ms/step - loss: 13.2136 - acc: 0.1770 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 44s 188ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 37s 157ms/step - loss: 13.2627 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 43s 184ms/step - loss: 13.2611 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 38s 163ms/step - loss: 13.2611 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 41s 177ms/step - loss: 13.2605 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 41s 177ms/step - loss: 13.2621 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 43s 185ms/step - loss: 13.2596 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 41s 173ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 44s 187ms/step - loss: 13.2617 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 11:31:33.516913
on validation data
11956/11956 [==============================] - 5s 412us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 250
learnrate: 0.1
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_43 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_25 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_18 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_26 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_27 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 42s 227ms/step - loss: 13.2041 - acc: 0.1766 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 40s 211ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 43s 229ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 42s 223ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 42s 226ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 41s 221ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 44s 235ms/step - loss: 13.2616 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 46s 244ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 45s 243ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 44s 235ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 11:39:39.179555
on validation data
11956/11956 [==============================] - 4s 371us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516