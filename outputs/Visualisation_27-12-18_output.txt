duser@8395372068e0:~$ python Visualisation_27-12-18.py 
Using TensorFlow backend.
Bild selected, Bild aug_farb_res
(227, 227, 3)
(227, 227, 3)
Anzahl Training Files:
46740
Anzahl Validation Files:
2989
Shape von immatrix1, 2 und gesamt
(11685, 154587)
(35055, 154587)
(46740, 154587)
46740
Shape von immatrix_val
Traceback (most recent call last):
  File "Visualisation_27-12-18.py", line 114, in <module>
    print(immatrix_val.shape)
NameError: name 'immatrix_val' is not defined
duser@8395372068e0:~$ vim Visualisation_27-12-18.py 
duser@8395372068e0:~$ python Visualisation_27-12-18.py 
Using TensorFlow backend.
Bild selected, Bild aug_farb_res
(227, 227, 3)
(227, 227, 3)
Anzahl Training Files:
46740
Anzahl Validation Files:
2989
Shape von immatrix1, 2 und gesamt
(11685, 154587)
(35055, 154587)
(46740, 154587)
46740
Shape von immatrix_val
(2989, 154587)
Label setzen
X_train shape: (46740, 227, 227, 3)
X_test shape: (2989, 227, 227, 3)
46740 train samples
2989 test samples
2018-12-27 16:06:47.547745: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-27 16:06:47.970540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 31.03GiB
2018-12-27 16:06:48.367450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2018-12-27 16:06:48.728283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2018-12-27 16:06:49.108972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2018-12-27 16:06:49.109057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2018-12-27 16:06:50.470852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-27 16:06:50.470894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2018-12-27 16:06:50.470908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2018-12-27 16:06:50.470916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2018-12-27 16:06:50.470924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2018-12-27 16:06:50.470934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2018-12-27 16:06:50.475544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30102 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2018-12-27 16:06:50.476004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2018-12-27 16:06:50.476358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2018-12-27 16:06:50.476688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
activation_1 (Activation)    (None, 55, 55, 96)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
activation_2 (Activation)    (None, 23, 23, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
activation_3 (Activation)    (None, 9, 9, 384)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
activation_4 (Activation)    (None, 7, 7, 384)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
activation_5 (Activation)    (None, 5, 5, 256)         0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
2018-12-27 16:07:09.815593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2018-12-27 16:07:09.815672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-27 16:07:09.815686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2018-12-27 16:07:09.815695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2018-12-27 16:07:09.815703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2018-12-27 16:07:09.815711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2018-12-27 16:07:09.815719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2018-12-27 16:07:09.817983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30102 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2018-12-27 16:07:09.818192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2018-12-27 16:07:09.818347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2018-12-27 16:07:09.818493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
Epoch 1/100
468/467 [==============================] - 94s 201ms/step - loss: 2.1925 - acc: 0.2216 - val_loss: 2.4521 - val_acc: 0.1787

Epoch 00001: val_loss improved from inf to 2.45215, saving model to /home/duser/Visualisation_27-12-18/tmp/weights.hdf5
Epoch 2/100
468/467 [==============================] - 49s 105ms/step - loss: 2.0582 - acc: 0.2761 - val_loss: 2.4903 - val_acc: 0.1716

Epoch 00002: val_loss did not improve from 2.45215
Epoch 3/100
468/467 [==============================] - 52s 112ms/step - loss: 1.9846 - acc: 0.2879 - val_loss: 2.5221 - val_acc: 0.1723

Epoch 00003: val_loss did not improve from 2.45215
Epoch 4/100
468/467 [==============================] - 64s 137ms/step - loss: 1.9016 - acc: 0.3156 - val_loss: 2.6125 - val_acc: 0.1703

Epoch 00004: val_loss did not improve from 2.45215
Epoch 5/100
468/467 [==============================] - 64s 138ms/step - loss: 1.8373 - acc: 0.3355 - val_loss: 2.4813 - val_acc: 0.1974

Epoch 00005: val_loss did not improve from 2.45215
Epoch 6/100
468/467 [==============================] - 63s 135ms/step - loss: 1.7857 - acc: 0.3596 - val_loss: 2.6708 - val_acc: 0.2312

Epoch 00006: val_loss did not improve from 2.45215
Epoch 7/100
468/467 [==============================] - 64s 136ms/step - loss: 1.7288 - acc: 0.3838 - val_loss: 2.6275 - val_acc: 0.2466

Epoch 00007: val_loss did not improve from 2.45215
Epoch 8/100
468/467 [==============================] - 64s 137ms/step - loss: 1.6705 - acc: 0.4114 - val_loss: 2.2966 - val_acc: 0.2723

Epoch 00008: val_loss improved from 2.45215 to 2.29664, saving model to /home/duser/Visualisation_27-12-18/tmp/weights.hdf5
Epoch 9/100
468/467 [==============================] - 59s 126ms/step - loss: 1.6019 - acc: 0.4391 - val_loss: 2.4020 - val_acc: 0.2710

Epoch 00009: val_loss did not improve from 2.29664
Epoch 10/100
468/467 [==============================] - 63s 134ms/step - loss: 1.5401 - acc: 0.4588 - val_loss: 2.5036 - val_acc: 0.3038

Epoch 00010: val_loss did not improve from 2.29664
Epoch 11/100
468/467 [==============================] - 61s 131ms/step - loss: 1.4673 - acc: 0.4860 - val_loss: 2.3678 - val_acc: 0.3218

Epoch 00011: val_loss did not improve from 2.29664
Epoch 12/100
468/467 [==============================] - 62s 132ms/step - loss: 1.3985 - acc: 0.5111 - val_loss: 2.4539 - val_acc: 0.3326

Epoch 00012: val_loss did not improve from 2.29664
Epoch 13/100
468/467 [==============================] - 64s 137ms/step - loss: 1.3462 - acc: 0.5297 - val_loss: 2.3801 - val_acc: 0.3111

Epoch 00013: val_loss did not improve from 2.29664
Epoch 14/100
468/467 [==============================] - 65s 138ms/step - loss: 1.2840 - acc: 0.5547 - val_loss: 2.2795 - val_acc: 0.3824

Epoch 00014: val_loss improved from 2.29664 to 2.27952, saving model to /home/duser/Visualisation_27-12-18/tmp/weights.hdf5
Epoch 15/100
468/467 [==============================] - 64s 137ms/step - loss: 1.2302 - acc: 0.5734 - val_loss: 2.2858 - val_acc: 0.3653

Epoch 00015: val_loss did not improve from 2.27952
Epoch 16/100
468/467 [==============================] - 63s 136ms/step - loss: 1.1687 - acc: 0.5963 - val_loss: 2.4006 - val_acc: 0.3727

Epoch 00016: val_loss did not improve from 2.27952
Epoch 17/100
468/467 [==============================] - 63s 135ms/step - loss: 1.1254 - acc: 0.6097 - val_loss: 2.5365 - val_acc: 0.3496

Epoch 00017: val_loss did not improve from 2.27952
Epoch 18/100
468/467 [==============================] - 65s 138ms/step - loss: 1.0611 - acc: 0.6342 - val_loss: 2.4357 - val_acc: 0.3647

Epoch 00018: val_loss did not improve from 2.27952
Epoch 19/100
468/467 [==============================] - 65s 139ms/step - loss: 1.0181 - acc: 0.6504 - val_loss: 2.4921 - val_acc: 0.3503

Epoch 00019: val_loss did not improve from 2.27952
Epoch 20/100
468/467 [==============================] - 64s 136ms/step - loss: 0.9702 - acc: 0.6659 - val_loss: 2.6024 - val_acc: 0.3369

Epoch 00020: val_loss did not improve from 2.27952
Epoch 21/100
468/467 [==============================] - 64s 136ms/step - loss: 0.9157 - acc: 0.6862 - val_loss: 2.7457 - val_acc: 0.3744

Epoch 00021: val_loss did not improve from 2.27952
Epoch 22/100
468/467 [==============================] - 62s 132ms/step - loss: 0.8693 - acc: 0.7017 - val_loss: 2.7129 - val_acc: 0.3630

Epoch 00022: val_loss did not improve from 2.27952
Epoch 23/100
468/467 [==============================] - 64s 138ms/step - loss: 0.8234 - acc: 0.7149 - val_loss: 2.6118 - val_acc: 0.3707

Epoch 00023: val_loss did not improve from 2.27952
Epoch 24/100
468/467 [==============================] - 65s 139ms/step - loss: 0.7774 - acc: 0.7352 - val_loss: 2.7042 - val_acc: 0.3700

Epoch 00024: val_loss did not improve from 2.27952
Epoch 25/100
468/467 [==============================] - 64s 137ms/step - loss: 0.7376 - acc: 0.7454 - val_loss: 2.6590 - val_acc: 0.3958

Epoch 00025: val_loss did not improve from 2.27952
Epoch 26/100
468/467 [==============================] - 64s 136ms/step - loss: 0.7016 - acc: 0.7595 - val_loss: 2.6350 - val_acc: 0.4379

Epoch 00026: val_loss did not improve from 2.27952
Epoch 27/100
468/467 [==============================] - 57s 122ms/step - loss: 0.6451 - acc: 0.7770 - val_loss: 2.6996 - val_acc: 0.4095

Epoch 00027: val_loss did not improve from 2.27952
Epoch 28/100
468/467 [==============================] - 62s 132ms/step - loss: 0.6171 - acc: 0.7861 - val_loss: 2.9814 - val_acc: 0.3513

Epoch 00028: val_loss did not improve from 2.27952
Epoch 29/100
468/467 [==============================] - 63s 134ms/step - loss: 0.5682 - acc: 0.8017 - val_loss: 2.7377 - val_acc: 0.4215

Epoch 00029: val_loss did not improve from 2.27952
Epoch 30/100
468/467 [==============================] - 54s 116ms/step - loss: 0.5306 - acc: 0.8164 - val_loss: 2.8005 - val_acc: 0.4048

Epoch 00030: val_loss did not improve from 2.27952
Epoch 31/100
468/467 [==============================] - 63s 135ms/step - loss: 0.5031 - acc: 0.8259 - val_loss: 2.9855 - val_acc: 0.4349

Epoch 00031: val_loss did not improve from 2.27952
Epoch 32/100
468/467 [==============================] - 60s 128ms/step - loss: 0.4661 - acc: 0.8378 - val_loss: 2.7033 - val_acc: 0.4155

Epoch 00032: val_loss did not improve from 2.27952
Epoch 33/100
468/467 [==============================] - 62s 133ms/step - loss: 0.4358 - acc: 0.8478 - val_loss: 2.9627 - val_acc: 0.4306

Epoch 00033: val_loss did not improve from 2.27952
Epoch 34/100
468/467 [==============================] - 61s 131ms/step - loss: 0.4019 - acc: 0.8592 - val_loss: 3.1087 - val_acc: 0.4112

Epoch 00034: val_loss did not improve from 2.27952
Epoch 35/100
468/467 [==============================] - 44s 94ms/step - loss: 0.3685 - acc: 0.8712 - val_loss: 3.2266 - val_acc: 0.3951

Epoch 00035: val_loss did not improve from 2.27952
Epoch 36/100
468/467 [==============================] - 65s 139ms/step - loss: 0.3447 - acc: 0.8788 - val_loss: 3.2794 - val_acc: 0.4112

Epoch 00036: val_loss did not improve from 2.27952
Epoch 37/100
468/467 [==============================] - 63s 135ms/step - loss: 0.3233 - acc: 0.8883 - val_loss: 3.3525 - val_acc: 0.4145

Epoch 00037: val_loss did not improve from 2.27952
Epoch 38/100
468/467 [==============================] - 45s 96ms/step - loss: 0.2906 - acc: 0.8992 - val_loss: 3.3771 - val_acc: 0.4282

Epoch 00038: val_loss did not improve from 2.27952
Epoch 39/100
468/467 [==============================] - 65s 138ms/step - loss: 0.2746 - acc: 0.9027 - val_loss: 3.9590 - val_acc: 0.3978

Epoch 00039: val_loss did not improve from 2.27952
Epoch 40/100
468/467 [==============================] - 51s 109ms/step - loss: 0.2533 - acc: 0.9105 - val_loss: 4.1669 - val_acc: 0.3694

Epoch 00040: val_loss did not improve from 2.27952
Epoch 41/100
468/467 [==============================] - 64s 137ms/step - loss: 0.2389 - acc: 0.9165 - val_loss: 3.9666 - val_acc: 0.3844

Epoch 00041: val_loss did not improve from 2.27952
Epoch 42/100
468/467 [==============================] - 63s 135ms/step - loss: 0.2287 - acc: 0.9200 - val_loss: 3.7980 - val_acc: 0.4031

Epoch 00042: val_loss did not improve from 2.27952
Epoch 43/100
468/467 [==============================] - 65s 138ms/step - loss: 0.2087 - acc: 0.9259 - val_loss: 4.0637 - val_acc: 0.3777

Epoch 00043: val_loss did not improve from 2.27952
Epoch 44/100
468/467 [==============================] - 65s 139ms/step - loss: 0.1935 - acc: 0.9336 - val_loss: 3.5537 - val_acc: 0.4583

Epoch 00044: val_loss did not improve from 2.27952
Epoch 45/100
468/467 [==============================] - 64s 136ms/step - loss: 0.1689 - acc: 0.9418 - val_loss: 3.8864 - val_acc: 0.4430

Epoch 00045: val_loss did not improve from 2.27952
Epoch 46/100
468/467 [==============================] - 64s 138ms/step - loss: 0.1577 - acc: 0.9452 - val_loss: 4.4200 - val_acc: 0.4229

Epoch 00046: val_loss did not improve from 2.27952
Epoch 47/100
468/467 [==============================] - 66s 140ms/step - loss: 0.1574 - acc: 0.9454 - val_loss: 4.1366 - val_acc: 0.3981

Epoch 00047: val_loss did not improve from 2.27952
Epoch 48/100
468/467 [==============================] - 64s 136ms/step - loss: 0.1454 - acc: 0.9487 - val_loss: 3.8456 - val_acc: 0.4413

Epoch 00048: val_loss did not improve from 2.27952
Epoch 49/100
468/467 [==============================] - 61s 131ms/step - loss: 0.1308 - acc: 0.9554 - val_loss: 4.0644 - val_acc: 0.4319

Epoch 00049: val_loss did not improve from 2.27952
Epoch 50/100
468/467 [==============================] - 64s 136ms/step - loss: 0.1216 - acc: 0.9581 - val_loss: 4.3527 - val_acc: 0.4219

Epoch 00050: val_loss did not improve from 2.27952
Epoch 51/100
468/467 [==============================] - 64s 138ms/step - loss: 0.1115 - acc: 0.9612 - val_loss: 4.1554 - val_acc: 0.4279

Epoch 00051: val_loss did not improve from 2.27952
Epoch 52/100
468/467 [==============================] - 64s 138ms/step - loss: 0.1106 - acc: 0.9618 - val_loss: 4.0055 - val_acc: 0.4175

Epoch 00052: val_loss did not improve from 2.27952
Epoch 53/100
468/467 [==============================] - 53s 112ms/step - loss: 0.0985 - acc: 0.9667 - val_loss: 4.0797 - val_acc: 0.4349

Epoch 00053: val_loss did not improve from 2.27952
Epoch 54/100
468/467 [==============================] - 63s 136ms/step - loss: 0.0994 - acc: 0.9662 - val_loss: 4.7386 - val_acc: 0.4152

Epoch 00054: val_loss did not improve from 2.27952
Epoch 55/100
468/467 [==============================] - 65s 139ms/step - loss: 0.0895 - acc: 0.9702 - val_loss: 4.4436 - val_acc: 0.4406

Epoch 00055: val_loss did not improve from 2.27952
Epoch 56/100
468/467 [==============================] - 65s 139ms/step - loss: 0.0963 - acc: 0.9680 - val_loss: 4.3297 - val_acc: 0.4363

Epoch 00056: val_loss did not improve from 2.27952
Epoch 57/100
468/467 [==============================] - 63s 134ms/step - loss: 0.0888 - acc: 0.9690 - val_loss: 4.4106 - val_acc: 0.4289

Epoch 00057: val_loss did not improve from 2.27952
Epoch 58/100
468/467 [==============================] - 62s 132ms/step - loss: 0.0758 - acc: 0.9750 - val_loss: 4.4679 - val_acc: 0.4450

Epoch 00058: val_loss did not improve from 2.27952
Epoch 59/100
468/467 [==============================] - 65s 140ms/step - loss: 0.0683 - acc: 0.9775 - val_loss: 4.6602 - val_acc: 0.4169

Epoch 00059: val_loss did not improve from 2.27952
Epoch 60/100
468/467 [==============================] - 62s 132ms/step - loss: 0.0730 - acc: 0.9758 - val_loss: 4.5577 - val_acc: 0.4316

Epoch 00060: val_loss did not improve from 2.27952
Epoch 61/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0669 - acc: 0.9770 - val_loss: 4.3276 - val_acc: 0.4410

Epoch 00061: val_loss did not improve from 2.27952
Epoch 62/100
468/467 [==============================] - 65s 139ms/step - loss: 0.0588 - acc: 0.9807 - val_loss: 4.6127 - val_acc: 0.4353

Epoch 00062: val_loss did not improve from 2.27952
Epoch 63/100
468/467 [==============================] - 66s 141ms/step - loss: 0.0596 - acc: 0.9804 - val_loss: 4.7084 - val_acc: 0.4202

Epoch 00063: val_loss did not improve from 2.27952
Epoch 64/100
468/467 [==============================] - 59s 127ms/step - loss: 0.0491 - acc: 0.9840 - val_loss: 4.7211 - val_acc: 0.4470

Epoch 00064: val_loss did not improve from 2.27952
Epoch 65/100
468/467 [==============================] - 64s 136ms/step - loss: 0.0626 - acc: 0.9792 - val_loss: 4.5392 - val_acc: 0.4463

Epoch 00065: val_loss did not improve from 2.27952
Epoch 66/100
468/467 [==============================] - 63s 135ms/step - loss: 0.0471 - acc: 0.9842 - val_loss: 4.7707 - val_acc: 0.4453

Epoch 00066: val_loss did not improve from 2.27952
Epoch 67/100
468/467 [==============================] - 62s 133ms/step - loss: 0.0590 - acc: 0.9814 - val_loss: 4.6734 - val_acc: 0.4406

Epoch 00067: val_loss did not improve from 2.27952
Epoch 68/100
468/467 [==============================] - 46s 99ms/step - loss: 0.0404 - acc: 0.9867 - val_loss: 5.1376 - val_acc: 0.4363

Epoch 00068: val_loss did not improve from 2.27952
Epoch 69/100
468/467 [==============================] - 47s 101ms/step - loss: 0.0570 - acc: 0.9814 - val_loss: 4.5464 - val_acc: 0.4376

Epoch 00069: val_loss did not improve from 2.27952
Epoch 70/100
468/467 [==============================] - 62s 132ms/step - loss: 0.0522 - acc: 0.9836 - val_loss: 5.0850 - val_acc: 0.4363

Epoch 00070: val_loss did not improve from 2.27952
Epoch 71/100
468/467 [==============================] - 64s 136ms/step - loss: 0.0373 - acc: 0.9874 - val_loss: 5.0338 - val_acc: 0.4289

Epoch 00071: val_loss did not improve from 2.27952
Epoch 72/100
468/467 [==============================] - 65s 139ms/step - loss: 0.0782 - acc: 0.9777 - val_loss: 4.3144 - val_acc: 0.4276

Epoch 00072: val_loss did not improve from 2.27952
Epoch 73/100
468/467 [==============================] - 64s 136ms/step - loss: 0.0420 - acc: 0.9865 - val_loss: 4.7359 - val_acc: 0.4493

Epoch 00073: val_loss did not improve from 2.27952
Epoch 74/100
468/467 [==============================] - 64s 138ms/step - loss: 0.0393 - acc: 0.9875 - val_loss: 5.1112 - val_acc: 0.4336

Epoch 00074: val_loss did not improve from 2.27952
Epoch 75/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0439 - acc: 0.9860 - val_loss: 4.9033 - val_acc: 0.4466

Epoch 00075: val_loss did not improve from 2.27952
Epoch 76/100
468/467 [==============================] - 62s 132ms/step - loss: 0.0241 - acc: 0.9921 - val_loss: 5.1213 - val_acc: 0.4433

Epoch 00076: val_loss did not improve from 2.27952
Epoch 77/100
468/467 [==============================] - 62s 133ms/step - loss: 0.0355 - acc: 0.9892 - val_loss: 5.0521 - val_acc: 0.4533

Epoch 00077: val_loss did not improve from 2.27952
Epoch 78/100
468/467 [==============================] - 62s 132ms/step - loss: 0.0388 - acc: 0.9878 - val_loss: 4.9117 - val_acc: 0.4510

Epoch 00078: val_loss did not improve from 2.27952
Epoch 79/100
468/467 [==============================] - 65s 139ms/step - loss: 0.0207 - acc: 0.9937 - val_loss: 5.3812 - val_acc: 0.4229

Epoch 00079: val_loss did not improve from 2.27952
Epoch 80/100
468/467 [==============================] - 58s 124ms/step - loss: 0.0300 - acc: 0.9902 - val_loss: 5.7074 - val_acc: 0.4316

Epoch 00080: val_loss did not improve from 2.27952
Epoch 81/100
468/467 [==============================] - 61s 130ms/step - loss: 0.0315 - acc: 0.9899 - val_loss: 5.3129 - val_acc: 0.4490

Epoch 00081: val_loss did not improve from 2.27952
Epoch 82/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0315 - acc: 0.9900 - val_loss: 5.0624 - val_acc: 0.4520

Epoch 00082: val_loss did not improve from 2.27952
Epoch 83/100
468/467 [==============================] - 62s 133ms/step - loss: 0.0367 - acc: 0.9880 - val_loss: 4.7933 - val_acc: 0.4486

Epoch 00083: val_loss did not improve from 2.27952
Epoch 84/100
468/467 [==============================] - 54s 116ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 4.8822 - val_acc: 0.4627

Epoch 00084: val_loss did not improve from 2.27952
Epoch 85/100
468/467 [==============================] - 63s 134ms/step - loss: 0.0325 - acc: 0.9897 - val_loss: 5.4819 - val_acc: 0.4299

Epoch 00085: val_loss did not improve from 2.27952
Epoch 86/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0195 - acc: 0.9935 - val_loss: 5.4436 - val_acc: 0.4323

Epoch 00086: val_loss did not improve from 2.27952
Epoch 87/100
468/467 [==============================] - 63s 135ms/step - loss: 0.0467 - acc: 0.9876 - val_loss: 4.9889 - val_acc: 0.4363

Epoch 00087: val_loss did not improve from 2.27952
Epoch 88/100
468/467 [==============================] - 63s 135ms/step - loss: 0.0160 - acc: 0.9952 - val_loss: 5.2859 - val_acc: 0.4403

Epoch 00088: val_loss did not improve from 2.27952
Epoch 89/100
468/467 [==============================] - 65s 138ms/step - loss: 0.0224 - acc: 0.9927 - val_loss: 5.0201 - val_acc: 0.4510

Epoch 00089: val_loss did not improve from 2.27952
Epoch 90/100
468/467 [==============================] - 66s 140ms/step - loss: 0.0226 - acc: 0.9930 - val_loss: 5.3559 - val_acc: 0.4356

Epoch 00090: val_loss did not improve from 2.27952
Epoch 91/100
468/467 [==============================] - 63s 134ms/step - loss: 0.0314 - acc: 0.9900 - val_loss: 5.2959 - val_acc: 0.4460

Epoch 00091: val_loss did not improve from 2.27952
Epoch 92/100
468/467 [==============================] - 60s 129ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 5.4468 - val_acc: 0.4333

Epoch 00092: val_loss did not improve from 2.27952
Epoch 93/100
468/467 [==============================] - 55s 117ms/step - loss: 0.0181 - acc: 0.9941 - val_loss: 5.3968 - val_acc: 0.4513

Epoch 00093: val_loss did not improve from 2.27952
Epoch 94/100
468/467 [==============================] - 57s 122ms/step - loss: 0.0187 - acc: 0.9942 - val_loss: 5.2604 - val_acc: 0.4660

Epoch 00094: val_loss did not improve from 2.27952
Epoch 95/100
468/467 [==============================] - 43s 91ms/step - loss: 0.0331 - acc: 0.9891 - val_loss: 5.2741 - val_acc: 0.4406

Epoch 00095: val_loss did not improve from 2.27952
Epoch 96/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0173 - acc: 0.9944 - val_loss: 5.1109 - val_acc: 0.4456

Epoch 00096: val_loss did not improve from 2.27952
Epoch 97/100
468/467 [==============================] - 58s 124ms/step - loss: 0.0161 - acc: 0.9952 - val_loss: 5.1338 - val_acc: 0.4583

Epoch 00097: val_loss did not improve from 2.27952
Epoch 98/100
468/467 [==============================] - 58s 123ms/step - loss: 0.0278 - acc: 0.9910 - val_loss: 4.8945 - val_acc: 0.4486

Epoch 00098: val_loss did not improve from 2.27952
Epoch 99/100
468/467 [==============================] - 57s 122ms/step - loss: 0.0200 - acc: 0.9939 - val_loss: 5.4432 - val_acc: 0.4490

Epoch 00099: val_loss did not improve from 2.27952
Epoch 100/100
468/467 [==============================] - 64s 137ms/step - loss: 0.0233 - acc: 0.9924 - val_loss: 5.2920 - val_acc: 0.4513

Epoch 00100: val_loss did not improve from 2.27952
2018-12-27 18:38:43.215701
on validation data
2989/2989 [==============================] - 1s 498us/step
accuaracy 45.13215122214127
Total loss 529.2028552993719
Model saved to: 
saved_models/27-12-18_visualisation.hdf5