duser@8395372068e0:~$ python repetition.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 200
learnrate: 0.01
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2019-01-06 08:36:57.837955: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-06 08:36:58.254655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.74GiB
2019-01-06 08:36:58.629125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 08:36:58.988806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 08:36:59.350243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-06 08:36:59.350330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-06 08:37:00.306048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-06 08:37:00.306090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-06 08:37:00.306103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-06 08:37:00.306112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-06 08:37:00.306121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-06 08:37:00.306129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-06 08:37:00.308423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29820 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-06 08:37:00.308831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-06 08:37:00.309157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-06 08:37:00.309460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
234/233 [==============================] - 51s 217ms/step - loss: 13.2185 - acc: 0.1767 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 44s 187ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 42s 178ms/step - loss: 13.2599 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 44s 186ms/step - loss: 13.2609 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 44s 188ms/step - loss: 13.2602 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 43s 184ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 43s 185ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 43s 186ms/step - loss: 13.2621 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 43s 182ms/step - loss: 13.2617 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 42s 180ms/step - loss: 13.2617 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 08:44:20.683800
on validation data
11956/11956 [==============================] - 5s 387us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 250
learnrate: 0.01
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 46s 246ms/step - loss: 13.2012 - acc: 0.1768 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 43s 229ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 36s 192ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 38s 201ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 41s 220ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 44s 236ms/step - loss: 13.2616 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 39s 208ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 43s 231ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 08:52:09.302465
on validation data
11956/11956 [==============================] - 4s 361us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 64
learnrate: 0.1
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 38s 52ms/step - loss: 13.5647 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 2/10
731/730 [==============================] - 36s 49ms/step - loss: 13.5823 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 3/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5830 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 4/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5815 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 5/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5808 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 6/10
731/730 [==============================] - 37s 50ms/step - loss: 13.5815 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 7/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5808 - acc: 0.1574 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 8/10
731/730 [==============================] - 37s 51ms/step - loss: 13.5830 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 9/10
731/730 [==============================] - 37s 50ms/step - loss: 13.5830 - acc: 0.1573 - val_loss: 14.7646 - val_acc: 0.0840
Epoch 10/10
731/730 [==============================] - 36s 50ms/step - loss: 13.5777 - acc: 0.1576 - val_loss: 14.7646 - val_acc: 0.0840
Test loss: 14.764584989921032
Test accuracy: 0.08397457343717808
2019-01-06 08:59:08.056330
on validation data
11956/11956 [==============================] - 4s 368us/step
accuaracy 8.397457343717809
Total loss 1476.4584989921032
batchsize: 100
learnrate: 0.1
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 40s 86ms/step - loss: 13.2359 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
468/467 [==============================] - 35s 75ms/step - loss: 13.2583 - acc: 0.1774 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
468/467 [==============================] - 37s 79ms/step - loss: 13.2625 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
468/467 [==============================] - 36s 78ms/step - loss: 13.2604 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
468/467 [==============================] - 35s 74ms/step - loss: 13.2630 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
468/467 [==============================] - 36s 78ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
468/467 [==============================] - 36s 77ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
468/467 [==============================] - 35s 75ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
468/467 [==============================] - 35s 75ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
468/467 [==============================] - 38s 82ms/step - loss: 13.2630 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 09:06:07.120569
on validation data
11956/11956 [==============================] - 4s 351us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 200
learnrate: 0.1
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_10 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_15 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 46s 198ms/step - loss: 13.2131 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 41s 175ms/step - loss: 13.2625 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 43s 183ms/step - loss: 13.2611 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 45s 191ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 44s 187ms/step - loss: 13.2627 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 41s 175ms/step - loss: 13.2627 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 42s 181ms/step - loss: 13.2620 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 40s 169ms/step - loss: 13.2622 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 45s 191ms/step - loss: 13.2622 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 42s 181ms/step - loss: 13.2617 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 09:14:08.380889
on validation data
11956/11956 [==============================] - 4s 365us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 250
learnrate: 0.1
filters: 96
maske: 3
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 57, 57, 96)        2688      
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 28, 28, 96)        0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 24, 24, 256)       614656    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_12 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_18 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,959,243
Trainable params: 50,959,243
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 44s 233ms/step - loss: 13.2041 - acc: 0.1768 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 42s 223ms/step - loss: 13.2612 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 43s 229ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 41s 221ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 42s 225ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 43s 232ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 44s 233ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 43s 228ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 41s 217ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-06 09:22:08.205404
on validation data
11956/11956 [==============================] - 5s 399us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 64
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_14 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_20 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_21 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 37s 51ms/step - loss: 1.8991 - acc: 0.3183 - val_loss: 2.2110 - val_acc: 0.2893
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 1.5828 - acc: 0.4463 - val_loss: 2.1547 - val_acc: 0.3131
Epoch 3/10
731/730 [==============================] - 36s 50ms/step - loss: 1.3326 - acc: 0.5335 - val_loss: 2.2182 - val_acc: 0.3346
Epoch 4/10
731/730 [==============================] - 36s 49ms/step - loss: 1.1495 - acc: 0.6032 - val_loss: 2.2676 - val_acc: 0.3625
Epoch 5/10
731/730 [==============================] - 33s 45ms/step - loss: 0.9913 - acc: 0.6620 - val_loss: 2.3726 - val_acc: 0.3720
Epoch 6/10
731/730 [==============================] - 36s 49ms/step - loss: 0.8662 - acc: 0.7063 - val_loss: 2.5307 - val_acc: 0.3490
Epoch 7/10
731/730 [==============================] - 35s 48ms/step - loss: 0.7513 - acc: 0.7402 - val_loss: 2.2526 - val_acc: 0.4109
Epoch 8/10
731/730 [==============================] - 36s 49ms/step - loss: 0.6462 - acc: 0.7806 - val_loss: 2.4268 - val_acc: 0.4166
Epoch 9/10
731/730 [==============================] - 37s 50ms/step - loss: 0.5550 - acc: 0.8100 - val_loss: 2.4538 - val_acc: 0.4180
Epoch 10/10
731/730 [==============================] - 36s 50ms/step - loss: 0.4821 - acc: 0.8343 - val_loss: 2.7142 - val_acc: 0.4216
Test loss: 2.7142205570166067
Test accuracy: 0.42162930747065985
2019-01-06 09:29:00.156799
on validation data
11956/11956 [==============================] - 4s 352us/step
accuaracy 42.162930747065985
Total loss 271.42205570166067
batchsize: 100
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_22 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_16 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_23 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_24 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 38s 80ms/step - loss: 1.9200 - acc: 0.3103 - val_loss: 2.3803 - val_acc: 0.2053
Epoch 2/10
468/467 [==============================] - 35s 75ms/step - loss: 1.6399 - acc: 0.4206 - val_loss: 2.2776 - val_acc: 0.3026
Epoch 3/10
468/467 [==============================] - 36s 77ms/step - loss: 1.4132 - acc: 0.5037 - val_loss: 2.1912 - val_acc: 0.3492
Epoch 4/10
468/467 [==============================] - 35s 76ms/step - loss: 1.2403 - acc: 0.5648 - val_loss: 2.2251 - val_acc: 0.3468
Epoch 5/10
468/467 [==============================] - 37s 79ms/step - loss: 1.0821 - acc: 0.6280 - val_loss: 2.2503 - val_acc: 0.3808
Epoch 6/10
468/467 [==============================] - 38s 81ms/step - loss: 0.9480 - acc: 0.6735 - val_loss: 2.3983 - val_acc: 0.3444
Epoch 7/10
468/467 [==============================] - 36s 77ms/step - loss: 0.8217 - acc: 0.7184 - val_loss: 2.4457 - val_acc: 0.4033
Epoch 8/10
468/467 [==============================] - 35s 74ms/step - loss: 0.7250 - acc: 0.7513 - val_loss: 2.5305 - val_acc: 0.3987
Epoch 9/10
468/467 [==============================] - 34s 72ms/step - loss: 0.6288 - acc: 0.7834 - val_loss: 2.5398 - val_acc: 0.4249
Epoch 10/10
468/467 [==============================] - 36s 77ms/step - loss: 0.5648 - acc: 0.8043 - val_loss: 2.7285 - val_acc: 0.4301
Test loss: 2.7285473493478416
Test accuracy: 0.4300769488123118
2019-01-06 09:35:51.185762
on validation data
11956/11956 [==============================] - 5s 397us/step
accuaracy 43.00769488123118
Total loss 272.8547349347842
batchsize: 200
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_43 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_25 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_18 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_26 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_27 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 44s 190ms/step - loss: 1.9504 - acc: 0.3012 - val_loss: 2.3831 - val_acc: 0.2588
Epoch 2/10
234/233 [==============================] - 40s 173ms/step - loss: 1.6693 - acc: 0.4129 - val_loss: 2.2727 - val_acc: 0.2903
Epoch 3/10
234/233 [==============================] - 44s 186ms/step - loss: 1.4975 - acc: 0.4775 - val_loss: 2.2943 - val_acc: 0.3270
Epoch 4/10
234/233 [==============================] - 35s 148ms/step - loss: 1.3309 - acc: 0.5363 - val_loss: 2.1633 - val_acc: 0.3400
Epoch 5/10
234/233 [==============================] - 32s 136ms/step - loss: 1.2145 - acc: 0.5782 - val_loss: 2.2750 - val_acc: 0.3356
Epoch 6/10
234/233 [==============================] - 45s 191ms/step - loss: 1.1068 - acc: 0.6184 - val_loss: 2.1228 - val_acc: 0.3888
Epoch 7/10
234/233 [==============================] - 44s 190ms/step - loss: 1.0014 - acc: 0.6566 - val_loss: 2.1910 - val_acc: 0.3993
Epoch 8/10
234/233 [==============================] - 43s 184ms/step - loss: 0.9155 - acc: 0.6857 - val_loss: 2.3092 - val_acc: 0.3832
Epoch 9/10
234/233 [==============================] - 43s 182ms/step - loss: 0.8410 - acc: 0.7128 - val_loss: 2.3606 - val_acc: 0.4057
Epoch 10/10
234/233 [==============================] - 43s 185ms/step - loss: 0.7546 - acc: 0.7420 - val_loss: 2.4965 - val_acc: 0.3899
Test loss: 2.4965355221584673
Test accuracy: 0.38992974236881744
2019-01-06 09:43:40.860356
on validation data
11956/11956 [==============================] - 5s 403us/step
accuaracy 38.99297423688174
Total loss 249.65355221584673
batchsize: 250
learnrate: 0.0001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_47 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_49 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_28 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_20 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_29 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_30 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 47s 249ms/step - loss: 1.9886 - acc: 0.2865 - val_loss: 2.3711 - val_acc: 0.2267
Epoch 2/10
187/186 [==============================] - 41s 220ms/step - loss: 1.7257 - acc: 0.3858 - val_loss: 2.1641 - val_acc: 0.3048
Epoch 3/10
187/186 [==============================] - 42s 225ms/step - loss: 1.5672 - acc: 0.4484 - val_loss: 2.1972 - val_acc: 0.2967
Epoch 4/10
187/186 [==============================] - 35s 185ms/step - loss: 1.4174 - acc: 0.5047 - val_loss: 2.2974 - val_acc: 0.3096
Epoch 5/10
187/186 [==============================] - 37s 200ms/step - loss: 1.2961 - acc: 0.5480 - val_loss: 2.2122 - val_acc: 0.3580
Epoch 6/10
187/186 [==============================] - 42s 223ms/step - loss: 1.1754 - acc: 0.5924 - val_loss: 2.1812 - val_acc: 0.3764
Epoch 7/10
187/186 [==============================] - 43s 230ms/step - loss: 1.0773 - acc: 0.6277 - val_loss: 2.2205 - val_acc: 0.3913
Epoch 8/10
187/186 [==============================] - 42s 223ms/step - loss: 0.9990 - acc: 0.6589 - val_loss: 2.1165 - val_acc: 0.4038
Epoch 9/10
187/186 [==============================] - 42s 227ms/step - loss: 0.8929 - acc: 0.6931 - val_loss: 2.2077 - val_acc: 0.4170
Epoch 10/10
187/186 [==============================] - 40s 215ms/step - loss: 0.8234 - acc: 0.7180 - val_loss: 2.1752 - val_acc: 0.4339
Test loss: 2.17516531622023
Test accuracy: 0.43392438940796096
2019-01-06 09:51:24.289050
on validation data
11956/11956 [==============================] - 5s 387us/step
accuaracy 43.3924389407961
Total loss 217.51653162202297
batchsize: 64
learnrate: 0.001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_53 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_55 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_31 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_22 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_32 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_33 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 40s 55ms/step - loss: 2.1407 - acc: 0.2342 - val_loss: 2.5928 - val_acc: 0.1651
Epoch 2/10
731/730 [==============================] - 38s 53ms/step - loss: 1.9837 - acc: 0.2859 - val_loss: 2.4209 - val_acc: 0.1986
Epoch 3/10
731/730 [==============================] - 38s 53ms/step - loss: 1.9331 - acc: 0.3087 - val_loss: 2.5758 - val_acc: 0.2114
Epoch 4/10
731/730 [==============================] - 39s 53ms/step - loss: 1.8865 - acc: 0.3252 - val_loss: 2.4085 - val_acc: 0.2176
Epoch 5/10
731/730 [==============================] - 38s 53ms/step - loss: 1.8331 - acc: 0.3448 - val_loss: 2.5398 - val_acc: 0.2135
Epoch 6/10
731/730 [==============================] - 38s 52ms/step - loss: 1.7937 - acc: 0.3625 - val_loss: 2.3973 - val_acc: 0.2446
Epoch 7/10
731/730 [==============================] - 38s 52ms/step - loss: 1.7646 - acc: 0.3697 - val_loss: 2.4181 - val_acc: 0.2756
Epoch 8/10
731/730 [==============================] - 39s 53ms/step - loss: 1.7495 - acc: 0.3792 - val_loss: 2.4029 - val_acc: 0.2651
Epoch 9/10
731/730 [==============================] - 39s 54ms/step - loss: 1.7292 - acc: 0.3880 - val_loss: 2.5191 - val_acc: 0.2589
Epoch 10/10
731/730 [==============================] - 38s 52ms/step - loss: 1.7092 - acc: 0.3931 - val_loss: 2.4106 - val_acc: 0.2631
Test loss: 2.4106467807919096
Test accuracy: 0.26313148209106646
2019-01-06 09:58:47.243653
on validation data
11956/11956 [==============================] - 5s 406us/step
accuaracy 26.313148209106647
Total loss 241.06467807919097
batchsize: 100
learnrate: 0.001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_57 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_59 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_60 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_34 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_24 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_35 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_36 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 41s 87ms/step - loss: 2.0677 - acc: 0.2661 - val_loss: 2.3716 - val_acc: 0.1931
Epoch 2/10
468/467 [==============================] - 41s 88ms/step - loss: 1.8791 - acc: 0.3254 - val_loss: 2.4458 - val_acc: 0.2103
Epoch 3/10
468/467 [==============================] - 40s 86ms/step - loss: 1.7989 - acc: 0.3583 - val_loss: 2.5549 - val_acc: 0.2303
Epoch 4/10
468/467 [==============================] - 39s 84ms/step - loss: 1.7386 - acc: 0.3825 - val_loss: 2.3448 - val_acc: 0.2605
Epoch 5/10
468/467 [==============================] - 38s 81ms/step - loss: 1.6892 - acc: 0.4016 - val_loss: 2.3471 - val_acc: 0.2472
Epoch 6/10
468/467 [==============================] - 41s 87ms/step - loss: 1.6590 - acc: 0.4100 - val_loss: 2.4466 - val_acc: 0.2522
Epoch 7/10
468/467 [==============================] - 40s 86ms/step - loss: 1.6254 - acc: 0.4256 - val_loss: 2.3906 - val_acc: 0.2794
Epoch 8/10
468/467 [==============================] - 41s 89ms/step - loss: 1.5860 - acc: 0.4384 - val_loss: 2.3145 - val_acc: 0.2678
Epoch 9/10
468/467 [==============================] - 43s 92ms/step - loss: 1.5542 - acc: 0.4530 - val_loss: 2.2541 - val_acc: 0.2932
Epoch 10/10
468/467 [==============================] - 42s 90ms/step - loss: 1.5406 - acc: 0.4577 - val_loss: 2.2899 - val_acc: 0.2861
Test loss: 2.2899137951530872
Test accuracy: 0.2861324857712271
2019-01-06 10:06:27.333663
on validation data
11956/11956 [==============================] - 5s 378us/step
accuaracy 28.613248577122707
Total loss 228.99137951530872
batchsize: 200
learnrate: 0.001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_63 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_64 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_65 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_37 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_26 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_38 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_39 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 46s 198ms/step - loss: 2.3034 - acc: 0.1753 - val_loss: 2.5450 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 44s 187ms/step - loss: 2.2714 - acc: 0.1773 - val_loss: 2.5304 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 44s 186ms/step - loss: 2.2711 - acc: 0.1773 - val_loss: 2.5253 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 37s 156ms/step - loss: 2.2705 - acc: 0.1772 - val_loss: 2.5488 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 38s 161ms/step - loss: 2.2704 - acc: 0.1763 - val_loss: 2.5256 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 42s 182ms/step - loss: 2.2700 - acc: 0.1772 - val_loss: 2.5132 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 40s 170ms/step - loss: 2.2702 - acc: 0.1763 - val_loss: 2.5345 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 39s 168ms/step - loss: 2.2698 - acc: 0.1772 - val_loss: 2.5274 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 43s 185ms/step - loss: 2.2701 - acc: 0.1773 - val_loss: 2.5566 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 43s 184ms/step - loss: 2.2699 - acc: 0.1756 - val_loss: 2.5458 - val_acc: 0.1010
Test loss: 2.545755969357355
Test accuracy: 0.10103713617092712
2019-01-06 10:14:16.082844
on validation data
11956/11956 [==============================] - 5s 400us/step
accuaracy 10.103713617092712
Total loss 254.57559693573552
batchsize: 250
learnrate: 0.001
filters: 96
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 56, 56, 96)        14208     
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_67 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_68 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_69 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_40 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_28 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_41 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_42 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,970,763
Trainable params: 50,970,763
Non-trainable params: 0
_________________________________________________________________
Traceback (most recent call last):
  File "repetition.py", line 377, in <module>
    run(250, 0.001, 96, 7)
  File "repetition.py", line 258, in run
    datagen_train.fit(X_train)
  File "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py", line 1363, in fit
    x = np.copy(x)
  File "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py", line 733, in copy
    return array(a, order=order, copy=True)
MemoryError