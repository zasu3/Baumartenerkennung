duser@8395372068e0:~$ python 10-01-19_best_rep_2.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 64
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
2019-01-10 14:34:08.864659: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-10 14:34:09.327936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.71GiB
2019-01-10 14:34:09.694165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 14:34:10.075167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 14:34:10.461812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 14:34:10.461894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-10 14:34:11.390119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-10 14:34:11.390161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-10 14:34:11.390173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-10 14:34:11.390181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-10 14:34:11.390189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-10 14:34:11.390197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-10 14:34:11.392487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29791 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-10 14:34:11.392908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-10 14:34:11.393243: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-10 14:34:11.393544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
731/730 [==============================] - 43s 58ms/step - loss: 1.8630 - acc: 0.3354 - val_loss: 2.2221 - val_acc: 0.3005
Epoch 2/30
731/730 [==============================] - 36s 49ms/step - loss: 1.5595 - acc: 0.4520 - val_loss: 2.2071 - val_acc: 0.3114
Epoch 3/30
731/730 [==============================] - 36s 50ms/step - loss: 1.3325 - acc: 0.5344 - val_loss: 2.2228 - val_acc: 0.3472
Epoch 4/30
731/730 [==============================] - 36s 49ms/step - loss: 1.1518 - acc: 0.6023 - val_loss: 2.2569 - val_acc: 0.3722
Epoch 5/30
731/730 [==============================] - 36s 49ms/step - loss: 0.9971 - acc: 0.6587 - val_loss: 2.2526 - val_acc: 0.3847
Epoch 6/30
731/730 [==============================] - 36s 49ms/step - loss: 0.8640 - acc: 0.7029 - val_loss: 2.4120 - val_acc: 0.4087
Epoch 7/30
731/730 [==============================] - 35s 49ms/step - loss: 0.7563 - acc: 0.7423 - val_loss: 2.3913 - val_acc: 0.4164
Epoch 8/30
731/730 [==============================] - 36s 49ms/step - loss: 0.6615 - acc: 0.7723 - val_loss: 2.4079 - val_acc: 0.4479
Epoch 9/30
731/730 [==============================] - 36s 49ms/step - loss: 0.5743 - acc: 0.8021 - val_loss: 2.3092 - val_acc: 0.4306
Epoch 10/30
731/730 [==============================] - 36s 49ms/step - loss: 0.5092 - acc: 0.8251 - val_loss: 2.4783 - val_acc: 0.4558
Epoch 11/30
731/730 [==============================] - 35s 48ms/step - loss: 0.4497 - acc: 0.8445 - val_loss: 2.7937 - val_acc: 0.4323
Epoch 12/30
731/730 [==============================] - 35s 49ms/step - loss: 0.4080 - acc: 0.8599 - val_loss: 2.5698 - val_acc: 0.4611
Epoch 13/30
731/730 [==============================] - 36s 49ms/step - loss: 0.3562 - acc: 0.8769 - val_loss: 2.6038 - val_acc: 0.4799
Epoch 14/30
731/730 [==============================] - 36s 49ms/step - loss: 0.3148 - acc: 0.8903 - val_loss: 3.1221 - val_acc: 0.4464
Epoch 15/30
731/730 [==============================] - 36s 49ms/step - loss: 0.2770 - acc: 0.9034 - val_loss: 3.1158 - val_acc: 0.4367
Epoch 16/30
731/730 [==============================] - 36s 49ms/step - loss: 0.2662 - acc: 0.9065 - val_loss: 3.0126 - val_acc: 0.4656
Epoch 17/30
731/730 [==============================] - 36s 49ms/step - loss: 0.2189 - acc: 0.9230 - val_loss: 3.4044 - val_acc: 0.4378
Epoch 18/30
731/730 [==============================] - 36s 49ms/step - loss: 0.2022 - acc: 0.9301 - val_loss: 3.3800 - val_acc: 0.4589
Epoch 19/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1970 - acc: 0.9307 - val_loss: 3.7653 - val_acc: 0.4126
Epoch 20/30
731/730 [==============================] - 36s 50ms/step - loss: 0.1733 - acc: 0.9396 - val_loss: 3.4285 - val_acc: 0.4593
Epoch 21/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1611 - acc: 0.9437 - val_loss: 3.3679 - val_acc: 0.4696
Epoch 22/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1532 - acc: 0.9473 - val_loss: 3.6492 - val_acc: 0.4699
Epoch 23/30
731/730 [==============================] - 35s 48ms/step - loss: 0.1424 - acc: 0.9511 - val_loss: 3.3762 - val_acc: 0.4898
Epoch 24/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1309 - acc: 0.9557 - val_loss: 3.7397 - val_acc: 0.4590
Epoch 25/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1272 - acc: 0.9556 - val_loss: 3.4738 - val_acc: 0.4623
Epoch 26/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1124 - acc: 0.9603 - val_loss: 3.7973 - val_acc: 0.4737
Epoch 27/30
731/730 [==============================] - 36s 50ms/step - loss: 0.1074 - acc: 0.9635 - val_loss: 3.7222 - val_acc: 0.4733
Epoch 28/30
731/730 [==============================] - 36s 49ms/step - loss: 0.1080 - acc: 0.9623 - val_loss: 3.9969 - val_acc: 0.4583
Epoch 29/30
731/730 [==============================] - 36s 49ms/step - loss: 0.0995 - acc: 0.9660 - val_loss: 4.0539 - val_acc: 0.4667
Epoch 30/30
731/730 [==============================] - 36s 49ms/step - loss: 0.0959 - acc: 0.9665 - val_loss: 3.6683 - val_acc: 0.4975
Test loss: 3.668312854055339
Test accuracy: 0.49749079961846926
2019-01-10 14:52:15.018764
on validation data
11956/11956 [==============================] - 4s 330us/step
accuaracy 49.749079961846924
Total loss 366.8312854055339
batchsize: 100
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
468/467 [==============================] - 39s 84ms/step - loss: 1.9120 - acc: 0.3132 - val_loss: 2.3443 - val_acc: 0.2610
Epoch 2/30
468/467 [==============================] - 39s 83ms/step - loss: 1.6201 - acc: 0.4225 - val_loss: 2.2277 - val_acc: 0.3131
Epoch 3/30
468/467 [==============================] - 37s 79ms/step - loss: 1.3929 - acc: 0.5116 - val_loss: 2.2665 - val_acc: 0.3561
Epoch 4/30
468/467 [==============================] - 37s 78ms/step - loss: 1.2353 - acc: 0.5689 - val_loss: 2.2149 - val_acc: 0.3566
Epoch 5/30
468/467 [==============================] - 36s 77ms/step - loss: 1.1015 - acc: 0.6212 - val_loss: 2.2067 - val_acc: 0.3756
Epoch 6/30
468/467 [==============================] - 39s 83ms/step - loss: 0.9895 - acc: 0.6627 - val_loss: 2.4437 - val_acc: 0.3721
Epoch 7/30
468/467 [==============================] - 41s 87ms/step - loss: 0.8733 - acc: 0.7021 - val_loss: 2.2760 - val_acc: 0.4202
Epoch 8/30
468/467 [==============================] - 36s 78ms/step - loss: 0.7798 - acc: 0.7328 - val_loss: 2.3183 - val_acc: 0.4272
Epoch 9/30
468/467 [==============================] - 39s 83ms/step - loss: 0.6868 - acc: 0.7666 - val_loss: 2.4960 - val_acc: 0.4285
Epoch 10/30
468/467 [==============================] - 38s 81ms/step - loss: 0.6156 - acc: 0.7897 - val_loss: 2.5819 - val_acc: 0.3923
Epoch 11/30
468/467 [==============================] - 39s 83ms/step - loss: 0.5473 - acc: 0.8120 - val_loss: 2.6431 - val_acc: 0.4166
Epoch 12/30
468/467 [==============================] - 37s 79ms/step - loss: 0.4826 - acc: 0.8336 - val_loss: 2.7028 - val_acc: 0.4409
Epoch 13/30
468/467 [==============================] - 37s 78ms/step - loss: 0.4361 - acc: 0.8478 - val_loss: 2.5990 - val_acc: 0.4586
Epoch 14/30
468/467 [==============================] - 36s 77ms/step - loss: 0.3818 - acc: 0.8665 - val_loss: 2.7231 - val_acc: 0.4441
Epoch 15/30
468/467 [==============================] - 38s 81ms/step - loss: 0.3480 - acc: 0.8781 - val_loss: 3.0132 - val_acc: 0.4335
Epoch 16/30
468/467 [==============================] - 38s 82ms/step - loss: 0.3022 - acc: 0.8952 - val_loss: 3.1843 - val_acc: 0.4361
Epoch 17/30
468/467 [==============================] - 39s 83ms/step - loss: 0.2747 - acc: 0.9038 - val_loss: 3.2553 - val_acc: 0.4408
Epoch 18/30
468/467 [==============================] - 35s 76ms/step - loss: 0.2535 - acc: 0.9104 - val_loss: 3.2569 - val_acc: 0.4624
Epoch 19/30
468/467 [==============================] - 38s 82ms/step - loss: 0.2198 - acc: 0.9229 - val_loss: 3.2276 - val_acc: 0.4572
Epoch 20/30
468/467 [==============================] - 38s 82ms/step - loss: 0.2083 - acc: 0.9272 - val_loss: 3.3259 - val_acc: 0.4542
Epoch 21/30
468/467 [==============================] - 39s 84ms/step - loss: 0.1902 - acc: 0.9330 - val_loss: 3.7130 - val_acc: 0.4149
Epoch 22/30
468/467 [==============================] - 38s 80ms/step - loss: 0.1764 - acc: 0.9373 - val_loss: 3.3943 - val_acc: 0.4622
Epoch 23/30
468/467 [==============================] - 35s 76ms/step - loss: 0.1650 - acc: 0.9420 - val_loss: 3.6394 - val_acc: 0.4665
Epoch 24/30
468/467 [==============================] - 37s 78ms/step - loss: 0.1669 - acc: 0.9428 - val_loss: 3.7307 - val_acc: 0.4450
Epoch 25/30
468/467 [==============================] - 40s 84ms/step - loss: 0.1401 - acc: 0.9506 - val_loss: 3.8033 - val_acc: 0.4507
Epoch 26/30
468/467 [==============================] - 36s 76ms/step - loss: 0.1338 - acc: 0.9536 - val_loss: 3.9639 - val_acc: 0.4436
Epoch 27/30
468/467 [==============================] - 35s 75ms/step - loss: 0.1313 - acc: 0.9536 - val_loss: 4.0193 - val_acc: 0.4514
Epoch 28/30
468/467 [==============================] - 41s 87ms/step - loss: 0.1232 - acc: 0.9576 - val_loss: 4.1826 - val_acc: 0.4122
Epoch 29/30
468/467 [==============================] - 36s 76ms/step - loss: 0.1178 - acc: 0.9586 - val_loss: 3.7878 - val_acc: 0.4512
Epoch 30/30
468/467 [==============================] - 36s 77ms/step - loss: 0.1104 - acc: 0.9618 - val_loss: 3.9536 - val_acc: 0.4609
Test loss: 3.9536080789550088
Test accuracy: 0.46085647375697714
2019-01-10 15:11:55.312378
on validation data
11956/11956 [==============================] - 4s 376us/step
accuaracy 46.08564737569771
Total loss 395.3608078955009
batchsize: 200
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
234/233 [==============================] - 47s 203ms/step - loss: 1.9569 - acc: 0.2989 - val_loss: 2.3952 - val_acc: 0.2221
Epoch 2/30
234/233 [==============================] - 44s 187ms/step - loss: 1.6817 - acc: 0.4045 - val_loss: 2.2475 - val_acc: 0.2864
Epoch 3/30
234/233 [==============================] - 44s 187ms/step - loss: 1.5155 - acc: 0.4707 - val_loss: 2.1991 - val_acc: 0.3303
Epoch 4/30
234/233 [==============================] - 41s 173ms/step - loss: 1.3830 - acc: 0.5180 - val_loss: 2.2018 - val_acc: 0.3246
Epoch 5/30
234/233 [==============================] - 43s 185ms/step - loss: 1.2638 - acc: 0.5603 - val_loss: 2.1533 - val_acc: 0.3784
Epoch 6/30
234/233 [==============================] - 40s 170ms/step - loss: 1.1555 - acc: 0.5970 - val_loss: 2.2745 - val_acc: 0.3674
Epoch 7/30
234/233 [==============================] - 43s 185ms/step - loss: 1.0647 - acc: 0.6326 - val_loss: 2.2364 - val_acc: 0.3730
Epoch 8/30
234/233 [==============================] - 39s 165ms/step - loss: 0.9659 - acc: 0.6690 - val_loss: 2.3279 - val_acc: 0.3815
Epoch 9/30
234/233 [==============================] - 42s 180ms/step - loss: 0.9002 - acc: 0.6937 - val_loss: 2.3679 - val_acc: 0.4032
Epoch 10/30
234/233 [==============================] - 43s 186ms/step - loss: 0.8060 - acc: 0.7227 - val_loss: 2.2803 - val_acc: 0.4142
Epoch 11/30
234/233 [==============================] - 44s 189ms/step - loss: 0.7561 - acc: 0.7404 - val_loss: 2.2499 - val_acc: 0.4232
Epoch 12/30
234/233 [==============================] - 43s 183ms/step - loss: 0.6961 - acc: 0.7592 - val_loss: 2.5397 - val_acc: 0.3970
Epoch 13/30
234/233 [==============================] - 40s 172ms/step - loss: 0.6393 - acc: 0.7799 - val_loss: 2.5949 - val_acc: 0.4031
Epoch 14/30
234/233 [==============================] - 43s 185ms/step - loss: 0.5773 - acc: 0.8033 - val_loss: 2.3929 - val_acc: 0.4317
Epoch 15/30
234/233 [==============================] - 43s 183ms/step - loss: 0.5191 - acc: 0.8199 - val_loss: 2.6020 - val_acc: 0.4281
Epoch 16/30
234/233 [==============================] - 43s 184ms/step - loss: 0.4809 - acc: 0.8332 - val_loss: 2.6429 - val_acc: 0.4406
Epoch 17/30
234/233 [==============================] - 44s 190ms/step - loss: 0.4429 - acc: 0.8462 - val_loss: 2.4820 - val_acc: 0.4383
Epoch 18/30
234/233 [==============================] - 44s 189ms/step - loss: 0.3991 - acc: 0.8607 - val_loss: 2.8096 - val_acc: 0.4487
Epoch 19/30
234/233 [==============================] - 44s 186ms/step - loss: 0.3701 - acc: 0.8702 - val_loss: 2.9666 - val_acc: 0.4458
Epoch 20/30
234/233 [==============================] - 42s 178ms/step - loss: 0.3411 - acc: 0.8808 - val_loss: 2.7722 - val_acc: 0.4440
Epoch 21/30
234/233 [==============================] - 44s 189ms/step - loss: 0.3169 - acc: 0.8890 - val_loss: 2.8042 - val_acc: 0.4524
Epoch 22/30
234/233 [==============================] - 42s 180ms/step - loss: 0.2825 - acc: 0.9014 - val_loss: 2.9811 - val_acc: 0.4709
Epoch 23/30
234/233 [==============================] - 37s 160ms/step - loss: 0.2632 - acc: 0.9080 - val_loss: 3.2548 - val_acc: 0.4363
Epoch 24/30
234/233 [==============================] - 36s 152ms/step - loss: 0.2336 - acc: 0.9177 - val_loss: 3.1941 - val_acc: 0.4471
Epoch 25/30
234/233 [==============================] - 39s 168ms/step - loss: 0.2399 - acc: 0.9151 - val_loss: 3.3037 - val_acc: 0.4383
Epoch 26/30
234/233 [==============================] - 44s 187ms/step - loss: 0.2037 - acc: 0.9284 - val_loss: 3.4017 - val_acc: 0.4353
Epoch 27/30
234/233 [==============================] - 41s 177ms/step - loss: 0.1776 - acc: 0.9380 - val_loss: 3.7054 - val_acc: 0.4258
Epoch 28/30
234/233 [==============================] - 44s 186ms/step - loss: 0.1740 - acc: 0.9376 - val_loss: 3.7228 - val_acc: 0.4264
Epoch 29/30
234/233 [==============================] - 43s 185ms/step - loss: 0.1576 - acc: 0.9440 - val_loss: 3.5956 - val_acc: 0.4525
Epoch 30/30
234/233 [==============================] - 42s 181ms/step - loss: 0.1684 - acc: 0.9411 - val_loss: 3.5602 - val_acc: 0.4423
Test loss: 3.560233413435297
Test accuracy: 0.4422883907761132
2019-01-10 15:33:57.276407
on validation data
11956/11956 [==============================] - 4s 344us/step
accuaracy 44.22883907761132
Total loss 356.0233413435297
batchsize: 250
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
187/186 [==============================] - 46s 248ms/step - loss: 1.9924 - acc: 0.2810 - val_loss: 2.4115 - val_acc: 0.2170
Epoch 2/30
187/186 [==============================] - 41s 222ms/step - loss: 1.7223 - acc: 0.3860 - val_loss: 2.2356 - val_acc: 0.3036
Epoch 3/30
187/186 [==============================] - 44s 234ms/step - loss: 1.5476 - acc: 0.4559 - val_loss: 2.1460 - val_acc: 0.3238
Epoch 4/30
187/186 [==============================] - 44s 236ms/step - loss: 1.4170 - acc: 0.5043 - val_loss: 2.1315 - val_acc: 0.3305
Epoch 5/30
187/186 [==============================] - 43s 229ms/step - loss: 1.3186 - acc: 0.5397 - val_loss: 2.3264 - val_acc: 0.3377
Epoch 6/30
187/186 [==============================] - 41s 222ms/step - loss: 1.2061 - acc: 0.5787 - val_loss: 2.3980 - val_acc: 0.3454
Epoch 7/30
187/186 [==============================] - 38s 206ms/step - loss: 1.1398 - acc: 0.6049 - val_loss: 2.2708 - val_acc: 0.3617
Epoch 8/30
187/186 [==============================] - 42s 224ms/step - loss: 1.0403 - acc: 0.6422 - val_loss: 2.2322 - val_acc: 0.3874
Epoch 9/30
187/186 [==============================] - 44s 234ms/step - loss: 0.9732 - acc: 0.6643 - val_loss: 2.2831 - val_acc: 0.4015
Epoch 10/30
187/186 [==============================] - 43s 228ms/step - loss: 0.8898 - acc: 0.6939 - val_loss: 2.2806 - val_acc: 0.3979
Epoch 11/30
187/186 [==============================] - 44s 233ms/step - loss: 0.8326 - acc: 0.7167 - val_loss: 2.4694 - val_acc: 0.4031
Epoch 12/30
187/186 [==============================] - 38s 205ms/step - loss: 0.7614 - acc: 0.7391 - val_loss: 2.3464 - val_acc: 0.4096
Epoch 13/30
187/186 [==============================] - 42s 224ms/step - loss: 0.6998 - acc: 0.7608 - val_loss: 2.3513 - val_acc: 0.4363
Epoch 14/30
187/186 [==============================] - 40s 215ms/step - loss: 0.6434 - acc: 0.7788 - val_loss: 2.4832 - val_acc: 0.4077
Epoch 15/30
187/186 [==============================] - 43s 230ms/step - loss: 0.6111 - acc: 0.7896 - val_loss: 2.4343 - val_acc: 0.4077
Epoch 16/30
187/186 [==============================] - 39s 210ms/step - loss: 0.5495 - acc: 0.8101 - val_loss: 2.7455 - val_acc: 0.4101
Epoch 17/30
187/186 [==============================] - 42s 225ms/step - loss: 0.5176 - acc: 0.8196 - val_loss: 2.6177 - val_acc: 0.4358
Epoch 18/30
187/186 [==============================] - 42s 226ms/step - loss: 0.4815 - acc: 0.8333 - val_loss: 2.8974 - val_acc: 0.4026
Epoch 19/30
187/186 [==============================] - 40s 214ms/step - loss: 0.4692 - acc: 0.8368 - val_loss: 2.6765 - val_acc: 0.4466
Epoch 20/30
187/186 [==============================] - 43s 228ms/step - loss: 0.4036 - acc: 0.8598 - val_loss: 3.0643 - val_acc: 0.3854
Epoch 21/30
187/186 [==============================] - 43s 229ms/step - loss: 0.3959 - acc: 0.8620 - val_loss: 2.7352 - val_acc: 0.4338
Epoch 22/30
187/186 [==============================] - 44s 233ms/step - loss: 0.3549 - acc: 0.8766 - val_loss: 3.0836 - val_acc: 0.4175
Epoch 23/30
187/186 [==============================] - 40s 213ms/step - loss: 0.3245 - acc: 0.8849 - val_loss: 3.0997 - val_acc: 0.4457
Epoch 24/30
187/186 [==============================] - 31s 164ms/step - loss: 0.3060 - acc: 0.8939 - val_loss: 3.0778 - val_acc: 0.4333
Epoch 25/30
187/186 [==============================] - 43s 229ms/step - loss: 0.2823 - acc: 0.9012 - val_loss: 3.1075 - val_acc: 0.4448
Epoch 26/30
187/186 [==============================] - 43s 232ms/step - loss: 0.2622 - acc: 0.9081 - val_loss: 3.2736 - val_acc: 0.4271
Epoch 27/30
187/186 [==============================] - 43s 228ms/step - loss: 0.2377 - acc: 0.9168 - val_loss: 3.3881 - val_acc: 0.4320
Epoch 28/30
187/186 [==============================] - 42s 226ms/step - loss: 0.2365 - acc: 0.9168 - val_loss: 3.5204 - val_acc: 0.4348
Epoch 29/30
187/186 [==============================] - 41s 221ms/step - loss: 0.2110 - acc: 0.9260 - val_loss: 3.6059 - val_acc: 0.4343
Epoch 30/30
187/186 [==============================] - 41s 220ms/step - loss: 0.1892 - acc: 0.9334 - val_loss: 3.6207 - val_acc: 0.4159
Test loss: 3.6206952192664503
Test accuracy: 0.4158581465273328
2019-01-10 15:55:43.047320
on validation data
11956/11956 [==============================] - 5s 387us/step
accuaracy 41.585814652733276
Total loss 362.06952192664505