duser@8395372068e0:~$ python 10-01-19_best_rep_3.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 50
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
2019-01-10 16:13:28.022279: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-10 16:13:28.422997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.71GiB
2019-01-10 16:13:28.773473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 16:13:29.148347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 16:13:29.534949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-10 16:13:29.535035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-10 16:13:30.492041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-10 16:13:30.492084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-10 16:13:30.492096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-10 16:13:30.492106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-10 16:13:30.492115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-10 16:13:30.492124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-10 16:13:30.494401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29791 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-10 16:13:30.494794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-10 16:13:30.495124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-10 16:13:30.495419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
935/934 [==============================] - 33s 35ms/step - loss: 1.8706 - acc: 0.3301 - val_loss: 2.2207 - val_acc: 0.2929
Epoch 2/30
935/934 [==============================] - 26s 27ms/step - loss: 1.5245 - acc: 0.4676 - val_loss: 2.3139 - val_acc: 0.2872
Epoch 3/30
935/934 [==============================] - 27s 28ms/step - loss: 1.2959 - acc: 0.5474 - val_loss: 2.3437 - val_acc: 0.3494
Epoch 4/30
935/934 [==============================] - 27s 29ms/step - loss: 1.1134 - acc: 0.6175 - val_loss: 2.3787 - val_acc: 0.3516
Epoch 5/30
935/934 [==============================] - 27s 29ms/step - loss: 0.9616 - acc: 0.6702 - val_loss: 2.3799 - val_acc: 0.3551
Epoch 6/30
935/934 [==============================] - 27s 29ms/step - loss: 0.8334 - acc: 0.7144 - val_loss: 2.5036 - val_acc: 0.3642
Epoch 7/30
935/934 [==============================] - 27s 28ms/step - loss: 0.7208 - acc: 0.7548 - val_loss: 2.3811 - val_acc: 0.4223
Epoch 8/30
935/934 [==============================] - 27s 28ms/step - loss: 0.6365 - acc: 0.7808 - val_loss: 2.4949 - val_acc: 0.4297
Epoch 9/30
935/934 [==============================] - 26s 28ms/step - loss: 0.5481 - acc: 0.8122 - val_loss: 2.5634 - val_acc: 0.4360
Epoch 10/30
935/934 [==============================] - 27s 29ms/step - loss: 0.4704 - acc: 0.8372 - val_loss: 2.6972 - val_acc: 0.4174
Epoch 11/30
935/934 [==============================] - 26s 28ms/step - loss: 0.4110 - acc: 0.8544 - val_loss: 2.7259 - val_acc: 0.4338
Epoch 12/30
935/934 [==============================] - 26s 28ms/step - loss: 0.3647 - acc: 0.8735 - val_loss: 2.9126 - val_acc: 0.4282
Epoch 13/30
935/934 [==============================] - 27s 29ms/step - loss: 0.3200 - acc: 0.8877 - val_loss: 2.8075 - val_acc: 0.4413
Epoch 14/30
935/934 [==============================] - 27s 28ms/step - loss: 0.2752 - acc: 0.9043 - val_loss: 3.3447 - val_acc: 0.4173
Epoch 15/30
935/934 [==============================] - 27s 29ms/step - loss: 0.2645 - acc: 0.9068 - val_loss: 3.3074 - val_acc: 0.4156
Epoch 16/30
935/934 [==============================] - 27s 29ms/step - loss: 0.2297 - acc: 0.9201 - val_loss: 3.4612 - val_acc: 0.4150
Epoch 17/30
935/934 [==============================] - 27s 29ms/step - loss: 0.2156 - acc: 0.9259 - val_loss: 3.3547 - val_acc: 0.4179
Epoch 18/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1823 - acc: 0.9364 - val_loss: 3.6423 - val_acc: 0.4339
Epoch 19/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1761 - acc: 0.9388 - val_loss: 3.7302 - val_acc: 0.4320
Epoch 20/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1661 - acc: 0.9431 - val_loss: 3.7029 - val_acc: 0.4244
Epoch 21/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1496 - acc: 0.9479 - val_loss: 3.6655 - val_acc: 0.4495
Epoch 22/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1453 - acc: 0.9495 - val_loss: 3.5090 - val_acc: 0.4350
Epoch 23/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1314 - acc: 0.9556 - val_loss: 3.8311 - val_acc: 0.4287
Epoch 24/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1325 - acc: 0.9543 - val_loss: 4.0284 - val_acc: 0.4148
Epoch 25/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1184 - acc: 0.9601 - val_loss: 3.7248 - val_acc: 0.4628
Epoch 26/30
935/934 [==============================] - 26s 28ms/step - loss: 0.1121 - acc: 0.9626 - val_loss: 4.2040 - val_acc: 0.4369
Epoch 27/30
935/934 [==============================] - 26s 28ms/step - loss: 0.1100 - acc: 0.9629 - val_loss: 4.1296 - val_acc: 0.4380
Epoch 28/30
935/934 [==============================] - 26s 28ms/step - loss: 0.0980 - acc: 0.9664 - val_loss: 4.1375 - val_acc: 0.4490
Epoch 29/30
935/934 [==============================] - 27s 29ms/step - loss: 0.1009 - acc: 0.9663 - val_loss: 4.1661 - val_acc: 0.4275
Epoch 30/30
935/934 [==============================] - 26s 28ms/step - loss: 0.0871 - acc: 0.9698 - val_loss: 4.1664 - val_acc: 0.4465
Test loss: 4.1664357569035015
Test accuracy: 0.4464703914352626
2019-01-10 16:26:58.501727
on validation data
11956/11956 [==============================] - 4s 332us/step
accuaracy 44.647039143526264
Total loss 416.64357569035013
batchsize: 32
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
1461/1460 [==============================] - 31s 21ms/step - loss: 1.8591 - acc: 0.3342 - val_loss: 2.1975 - val_acc: 0.2978
Epoch 2/30
1461/1460 [==============================] - 31s 21ms/step - loss: 1.5080 - acc: 0.4741 - val_loss: 2.1502 - val_acc: 0.3396
Epoch 3/30
1461/1460 [==============================] - 31s 21ms/step - loss: 1.2720 - acc: 0.5567 - val_loss: 2.2447 - val_acc: 0.3499
Epoch 4/30
1461/1460 [==============================] - 31s 21ms/step - loss: 1.0918 - acc: 0.6245 - val_loss: 2.3366 - val_acc: 0.3685
Epoch 5/30
1461/1460 [==============================] - 30s 20ms/step - loss: 0.9252 - acc: 0.6852 - val_loss: 2.3752 - val_acc: 0.4014
Epoch 6/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.8026 - acc: 0.7285 - val_loss: 2.4904 - val_acc: 0.3847
Epoch 7/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.6880 - acc: 0.7656 - val_loss: 2.5216 - val_acc: 0.4269
Epoch 8/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.5935 - acc: 0.7970 - val_loss: 2.5643 - val_acc: 0.3995
Epoch 9/30
1461/1460 [==============================] - 31s 22ms/step - loss: 0.5189 - acc: 0.8215 - val_loss: 2.6492 - val_acc: 0.4121
Epoch 10/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.4528 - acc: 0.8437 - val_loss: 2.8928 - val_acc: 0.4294
Epoch 11/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.4036 - acc: 0.8632 - val_loss: 3.0174 - val_acc: 0.4224
Epoch 12/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.3551 - acc: 0.8795 - val_loss: 3.0360 - val_acc: 0.4305
Epoch 13/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.3082 - acc: 0.8934 - val_loss: 3.2193 - val_acc: 0.4220
Epoch 14/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.2836 - acc: 0.9020 - val_loss: 3.2950 - val_acc: 0.4267
Epoch 15/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.2555 - acc: 0.9110 - val_loss: 3.4100 - val_acc: 0.4403
Epoch 16/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.2342 - acc: 0.9187 - val_loss: 3.4756 - val_acc: 0.4494
Epoch 17/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.2126 - acc: 0.9271 - val_loss: 3.4069 - val_acc: 0.4470
Epoch 18/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1887 - acc: 0.9356 - val_loss: 3.4516 - val_acc: 0.4493
Epoch 19/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1756 - acc: 0.9389 - val_loss: 4.0493 - val_acc: 0.4152
Epoch 20/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.1634 - acc: 0.9440 - val_loss: 3.8213 - val_acc: 0.4425
Epoch 21/30
1461/1460 [==============================] - 31s 22ms/step - loss: 0.1514 - acc: 0.9479 - val_loss: 4.0362 - val_acc: 0.4445
Epoch 22/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1426 - acc: 0.9510 - val_loss: 3.9469 - val_acc: 0.4451
Epoch 23/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.1425 - acc: 0.9511 - val_loss: 3.9478 - val_acc: 0.4400
Epoch 24/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.1233 - acc: 0.9578 - val_loss: 4.1858 - val_acc: 0.4319
Epoch 25/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1172 - acc: 0.9604 - val_loss: 4.0775 - val_acc: 0.4365
Epoch 26/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1156 - acc: 0.9609 - val_loss: 4.0517 - val_acc: 0.4459
Epoch 27/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1149 - acc: 0.9606 - val_loss: 4.2569 - val_acc: 0.4362
Epoch 28/30
1461/1460 [==============================] - 31s 21ms/step - loss: 0.1066 - acc: 0.9639 - val_loss: 3.7146 - val_acc: 0.4614
Epoch 29/30
1461/1460 [==============================] - 32s 22ms/step - loss: 0.0988 - acc: 0.9667 - val_loss: 4.2276 - val_acc: 0.4395
Epoch 30/30
1461/1460 [==============================] - 30s 21ms/step - loss: 0.0958 - acc: 0.9680 - val_loss: 4.2276 - val_acc: 0.4601
Test loss: 4.227586042685587
Test accuracy: 0.4601037136365355
2019-01-10 16:43:15.420477
on validation data
11956/11956 [==============================] - 4s 349us/step
accuaracy 46.010371363653555
Total loss 422.7586042685587
batchsize: 10
learnrate: 0.0001
filters: 32
maske: 7
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 56, 56, 32)        4736      
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 32)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       205056    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,551,691
Trainable params: 50,551,691
Non-trainable params: 0
_________________________________________________________________
Epoch 1/30
4674/4674 [==============================] - 63s 13ms/step - loss: 1.8277 - acc: 0.3469 - val_loss: 2.2122 - val_acc: 0.2947
Epoch 2/30
4674/4674 [==============================] - 66s 14ms/step - loss: 1.5290 - acc: 0.4692 - val_loss: 2.2453 - val_acc: 0.3112
Epoch 3/30
4674/4674 [==============================] - 65s 14ms/step - loss: 1.3236 - acc: 0.5411 - val_loss: 2.0789 - val_acc: 0.3569
Epoch 4/30
4674/4674 [==============================] - 65s 14ms/step - loss: 1.1418 - acc: 0.6091 - val_loss: 2.2542 - val_acc: 0.3813
Epoch 5/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.9899 - acc: 0.6617 - val_loss: 2.4923 - val_acc: 0.3568
Epoch 6/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.8589 - acc: 0.7054 - val_loss: 2.2041 - val_acc: 0.4079
Epoch 7/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.7546 - acc: 0.7430 - val_loss: 2.5962 - val_acc: 0.3978
Epoch 8/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.6576 - acc: 0.7781 - val_loss: 2.7885 - val_acc: 0.4061
Epoch 9/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.5880 - acc: 0.7997 - val_loss: 2.6898 - val_acc: 0.4241
Epoch 10/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.5147 - acc: 0.8240 - val_loss: 2.9983 - val_acc: 0.4186
Epoch 11/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.4638 - acc: 0.8413 - val_loss: 2.8751 - val_acc: 0.4150
Epoch 12/30
4674/4674 [==============================] - 66s 14ms/step - loss: 0.4160 - acc: 0.8570 - val_loss: 3.0051 - val_acc: 0.4316
Epoch 13/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.3674 - acc: 0.8751 - val_loss: 3.1611 - val_acc: 0.4281
Epoch 14/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.3356 - acc: 0.8855 - val_loss: 3.5138 - val_acc: 0.4192
Epoch 15/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.3070 - acc: 0.8962 - val_loss: 3.3927 - val_acc: 0.4154
Epoch 16/30
4674/4674 [==============================] - 63s 14ms/step - loss: 0.2863 - acc: 0.9035 - val_loss: 3.3694 - val_acc: 0.4303
Epoch 17/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.2687 - acc: 0.9109 - val_loss: 3.2277 - val_acc: 0.4336
Epoch 18/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.2467 - acc: 0.9179 - val_loss: 3.4491 - val_acc: 0.4124
Epoch 19/30
4674/4674 [==============================] - 63s 14ms/step - loss: 0.2305 - acc: 0.9240 - val_loss: 3.5404 - val_acc: 0.4370
Epoch 20/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.2245 - acc: 0.9253 - val_loss: 3.7686 - val_acc: 0.4034
Epoch 21/30
4674/4674 [==============================] - 63s 13ms/step - loss: 0.2090 - acc: 0.9312 - val_loss: 3.4520 - val_acc: 0.4387
Epoch 22/30
4674/4674 [==============================] - 65s 14ms/step - loss: 0.1950 - acc: 0.9361 - val_loss: 3.6623 - val_acc: 0.4575
Epoch 23/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.1876 - acc: 0.9385 - val_loss: 3.4627 - val_acc: 0.4736
Epoch 24/30
4674/4674 [==============================] - 63s 13ms/step - loss: 0.1785 - acc: 0.9408 - val_loss: 3.6774 - val_acc: 0.4430
Epoch 25/30
4674/4674 [==============================] - 63s 14ms/step - loss: 0.1793 - acc: 0.9422 - val_loss: 4.1266 - val_acc: 0.4006
Epoch 26/30
4674/4674 [==============================] - 63s 13ms/step - loss: 0.1634 - acc: 0.9483 - val_loss: 3.8226 - val_acc: 0.4392
Epoch 27/30
4674/4674 [==============================] - 63s 13ms/step - loss: 0.1620 - acc: 0.9486 - val_loss: 3.9269 - val_acc: 0.4323
Epoch 28/30
4674/4674 [==============================] - 64s 14ms/step - loss: 0.1564 - acc: 0.9507 - val_loss: 3.9592 - val_acc: 0.4362
Epoch 29/30
4674/4674 [==============================] - 63s 13ms/step - loss: 0.1506 - acc: 0.9519 - val_loss: 3.8728 - val_acc: 0.4603
Epoch 30/30
4674/4674 [==============================] - 63s 14ms/step - loss: 0.1463 - acc: 0.9547 - val_loss: 4.0061 - val_acc: 0.4373
Test loss: 4.006118106140106
Test accuracy: 0.4372699899631984
2019-01-10 17:16:11.502424
on validation data
11956/11956 [==============================] - 5s 384us/step
accuaracy 43.726998996319836
Total loss 400.6118106140106