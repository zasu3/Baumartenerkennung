duser@8395372068e0:~$ python repetition.py 
Using TensorFlow backend.
Shape von immatrix1, 2 und gesamt
(35055, 154587)
(46740, 154587)
Shape von immatrix_val1, _valrot und gesamt
(8967, 154587)
(11956, 154587)
Label setzen
batchsize: 64
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_2 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_3 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2019-01-05 20:40:54.149720: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-01-05 20:40:54.539886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
totalMemory: 31.73GiB freeMemory: 30.74GiB
2019-01-05 20:40:54.893069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 20:40:55.273162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 2 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0e:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 20:40:55.653309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 3 with properties: 
name: Tesla V100-DGXS-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0f:00.0
totalMemory: 31.74GiB freeMemory: 31.32GiB
2019-01-05 20:40:55.653395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1, 2, 3
2019-01-05 20:40:56.604625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-05 20:40:56.604669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 2 3 
2019-01-05 20:40:56.604681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y Y Y 
2019-01-05 20:40:56.604690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N Y Y 
2019-01-05 20:40:56.604698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 2:   Y Y N Y 
2019-01-05 20:40:56.604706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 3:   Y Y Y N 
2019-01-05 20:40:56.606993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 29820 MB memory) -> physical GPU (device: 0, name: Tesla V100-DGXS-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2019-01-05 20:40:56.607412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30387 MB memory) -> physical GPU (device: 1, name: Tesla V100-DGXS-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2019-01-05 20:40:56.607742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30387 MB memory) -> physical GPU (device: 2, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0e:00.0, compute capability: 7.0)
2019-01-05 20:40:56.608034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30387 MB memory) -> physical GPU (device: 3, name: Tesla V100-DGXS-32GB, pci bus id: 0000:0f:00.0, compute capability: 7.0)
731/730 [==============================] - 43s 59ms/step - loss: 1.9280 - acc: 0.3089 - val_loss: 2.2913 - val_acc: 0.2204
Epoch 2/10
731/730 [==============================] - 36s 49ms/step - loss: 1.6412 - acc: 0.4237 - val_loss: 2.2885 - val_acc: 0.3019
Epoch 3/10
731/730 [==============================] - 36s 49ms/step - loss: 1.4371 - acc: 0.4995 - val_loss: 2.1226 - val_acc: 0.3419
Epoch 4/10
731/730 [==============================] - 37s 50ms/step - loss: 1.2459 - acc: 0.5689 - val_loss: 2.7117 - val_acc: 0.3372
Epoch 5/10
731/730 [==============================] - 37s 50ms/step - loss: 1.1040 - acc: 0.6203 - val_loss: 2.2995 - val_acc: 0.3760
Epoch 6/10
731/730 [==============================] - 37s 50ms/step - loss: 0.9675 - acc: 0.6692 - val_loss: 2.1768 - val_acc: 0.3966
Epoch 7/10
731/730 [==============================] - 37s 51ms/step - loss: 0.8499 - acc: 0.7107 - val_loss: 2.6509 - val_acc: 0.4013
Epoch 8/10
731/730 [==============================] - 37s 50ms/step - loss: 0.7526 - acc: 0.7434 - val_loss: 2.2804 - val_acc: 0.4240
Epoch 9/10
731/730 [==============================] - 36s 50ms/step - loss: 0.6598 - acc: 0.7750 - val_loss: 2.7272 - val_acc: 0.3634
Epoch 10/10
731/730 [==============================] - 36s 50ms/step - loss: 0.5719 - acc: 0.8039 - val_loss: 2.4218 - val_acc: 0.4353
Test loss: 2.421756456431915
Test accuracy: 0.4352626296220794
2019-01-05 20:47:11.362882
on validation data
11956/11956 [==============================] - 5s 403us/step
accuaracy 43.52626296220794
Total loss 242.17564564319153
batchsize: 100
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_4 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 39s 84ms/step - loss: 1.9341 - acc: 0.3064 - val_loss: 2.2120 - val_acc: 0.2531
Epoch 2/10
468/467 [==============================] - 38s 81ms/step - loss: 1.6305 - acc: 0.4269 - val_loss: 2.1638 - val_acc: 0.2959
Epoch 3/10
468/467 [==============================] - 38s 82ms/step - loss: 1.4406 - acc: 0.4989 - val_loss: 2.2884 - val_acc: 0.3379
Epoch 4/10
468/467 [==============================] - 36s 77ms/step - loss: 1.2657 - acc: 0.5578 - val_loss: 2.1722 - val_acc: 0.3518
Epoch 5/10
468/467 [==============================] - 38s 80ms/step - loss: 1.1308 - acc: 0.6099 - val_loss: 2.3200 - val_acc: 0.3821
Epoch 6/10
468/467 [==============================] - 36s 77ms/step - loss: 0.9897 - acc: 0.6613 - val_loss: 2.2345 - val_acc: 0.3875
Epoch 7/10
468/467 [==============================] - 37s 80ms/step - loss: 0.8824 - acc: 0.6991 - val_loss: 2.4013 - val_acc: 0.3790
Epoch 8/10
468/467 [==============================] - 38s 81ms/step - loss: 0.7839 - acc: 0.7321 - val_loss: 2.3209 - val_acc: 0.4418
Epoch 9/10
468/467 [==============================] - 37s 80ms/step - loss: 0.6850 - acc: 0.7656 - val_loss: 2.5079 - val_acc: 0.3833
Epoch 10/10
468/467 [==============================] - 39s 83ms/step - loss: 0.6077 - acc: 0.7926 - val_loss: 2.4638 - val_acc: 0.4329
Test loss: 2.463847104344092
Test accuracy: 0.43292070926731346
2019-01-05 20:54:22.264254
on validation data
11956/11956 [==============================] - 5s 405us/step
accuaracy 43.29207092673135
Total loss 246.3847104344092
batchsize: 200
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_11 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 9216)              9446400   
_________________________________________________________________
dropout_6 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 4096)              37752832  
_________________________________________________________________
dense_9 (Dense)              (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 48s 203ms/step - loss: 1.9825 - acc: 0.2901 - val_loss: 2.2715 - val_acc: 0.2353
Epoch 2/10
234/233 [==============================] - 45s 192ms/step - loss: 1.7203 - acc: 0.3912 - val_loss: 2.2826 - val_acc: 0.2775
Epoch 3/10
234/233 [==============================] - 45s 193ms/step - loss: 1.5498 - acc: 0.4572 - val_loss: 2.1793 - val_acc: 0.3368
Epoch 4/10
234/233 [==============================] - 45s 192ms/step - loss: 1.4034 - acc: 0.5086 - val_loss: 2.2108 - val_acc: 0.3336
Epoch 5/10
234/233 [==============================] - 40s 172ms/step - loss: 1.2710 - acc: 0.5575 - val_loss: 2.1927 - val_acc: 0.3567
Epoch 6/10
234/233 [==============================] - 45s 191ms/step - loss: 1.1387 - acc: 0.6081 - val_loss: 2.3391 - val_acc: 0.3689
Epoch 7/10
234/233 [==============================] - 44s 187ms/step - loss: 1.0288 - acc: 0.6468 - val_loss: 2.3416 - val_acc: 0.3678
Epoch 8/10
234/233 [==============================] - 43s 183ms/step - loss: 0.9391 - acc: 0.6781 - val_loss: 2.3007 - val_acc: 0.4040
Epoch 9/10
234/233 [==============================] - 46s 195ms/step - loss: 0.8521 - acc: 0.7087 - val_loss: 2.2826 - val_acc: 0.3960
Epoch 10/10
234/233 [==============================] - 44s 189ms/step - loss: 0.7652 - acc: 0.7389 - val_loss: 2.3377 - val_acc: 0.4097
Test loss: 2.3376826260073122
Test accuracy: 0.40966878552706437
2019-01-05 21:02:39.942902
on validation data
11956/11956 [==============================] - 4s 365us/step
accuaracy 40.96687855270644
Total loss 233.76826260073122
batchsize: 250
learnrate: 0.0001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_16 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_8 (Dropout)          (None, 9216)              0         
_________________________________________________________________
dense_11 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_12 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 53s 284ms/step - loss: 1.9913 - acc: 0.2881 - val_loss: 2.3024 - val_acc: 0.2179
Epoch 2/10
187/186 [==============================] - 46s 247ms/step - loss: 1.7379 - acc: 0.3829 - val_loss: 2.1566 - val_acc: 0.3208
Epoch 3/10
187/186 [==============================] - 43s 230ms/step - loss: 1.5687 - acc: 0.4505 - val_loss: 2.1666 - val_acc: 0.3337
Epoch 4/10
187/186 [==============================] - 46s 246ms/step - loss: 1.4329 - acc: 0.4965 - val_loss: 2.1395 - val_acc: 0.3331
Epoch 5/10
187/186 [==============================] - 46s 247ms/step - loss: 1.3162 - acc: 0.5396 - val_loss: 2.1328 - val_acc: 0.3413
Epoch 6/10
187/186 [==============================] - 45s 239ms/step - loss: 1.2118 - acc: 0.5796 - val_loss: 2.3572 - val_acc: 0.3326
Epoch 7/10
187/186 [==============================] - 41s 221ms/step - loss: 1.1151 - acc: 0.6127 - val_loss: 2.2908 - val_acc: 0.3713
Epoch 8/10
187/186 [==============================] - 47s 250ms/step - loss: 1.0308 - acc: 0.6438 - val_loss: 2.2630 - val_acc: 0.3793
Epoch 9/10
187/186 [==============================] - 40s 214ms/step - loss: 0.9654 - acc: 0.6692 - val_loss: 2.3039 - val_acc: 0.3608
Epoch 10/10
187/186 [==============================] - 46s 246ms/step - loss: 0.8671 - acc: 0.7042 - val_loss: 2.1996 - val_acc: 0.4144
Test loss: 2.1995816112721234
Test accuracy: 0.41435262630639086
2019-01-05 21:11:08.399045
on validation data
11956/11956 [==============================] - 4s 376us/step
accuaracy 41.43526263063909
Total loss 219.95816112721235
batchsize: 64
learnrate: 0.001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_21 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_10 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_15 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 37s 51ms/step - loss: 2.2853 - acc: 0.1736 - val_loss: 2.5082 - val_acc: 0.1010
Epoch 2/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2716 - acc: 0.1765 - val_loss: 2.5633 - val_acc: 0.1010
Epoch 3/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2707 - acc: 0.1764 - val_loss: 2.5642 - val_acc: 0.1010
Epoch 4/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2705 - acc: 0.1767 - val_loss: 2.5288 - val_acc: 0.1010
Epoch 5/10
731/730 [==============================] - 36s 50ms/step - loss: 2.2703 - acc: 0.1766 - val_loss: 2.5263 - val_acc: 0.1010
Epoch 6/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2704 - acc: 0.1774 - val_loss: 2.5382 - val_acc: 0.1010
Epoch 7/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2703 - acc: 0.1772 - val_loss: 2.5271 - val_acc: 0.1010
Epoch 8/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2700 - acc: 0.1773 - val_loss: 2.5304 - val_acc: 0.1010
Epoch 9/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2700 - acc: 0.1772 - val_loss: 2.5038 - val_acc: 0.1010
Epoch 10/10
731/730 [==============================] - 36s 49ms/step - loss: 2.2701 - acc: 0.1772 - val_loss: 2.5482 - val_acc: 0.1010
Test loss: 2.5481938854752277
Test accuracy: 0.10103713617092712
2019-01-05 21:18:02.056635
on validation data
11956/11956 [==============================] - 4s 371us/step
accuaracy 10.103713617092712
Total loss 254.81938854752278
batchsize: 100
learnrate: 0.001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_26 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_29 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_12 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_18 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 37s 79ms/step - loss: 2.0655 - acc: 0.2618 - val_loss: 2.4606 - val_acc: 0.1665
Epoch 2/10
468/467 [==============================] - 37s 80ms/step - loss: 1.9422 - acc: 0.3011 - val_loss: 2.5944 - val_acc: 0.1629
Epoch 3/10
468/467 [==============================] - 36s 76ms/step - loss: 1.8977 - acc: 0.3204 - val_loss: 2.7135 - val_acc: 0.1751
Epoch 4/10
468/467 [==============================] - 38s 82ms/step - loss: 1.8719 - acc: 0.3295 - val_loss: 2.4169 - val_acc: 0.2451
Epoch 5/10
468/467 [==============================] - 39s 82ms/step - loss: 1.8488 - acc: 0.3431 - val_loss: 2.4281 - val_acc: 0.2380
Epoch 6/10
468/467 [==============================] - 37s 78ms/step - loss: 1.8175 - acc: 0.3565 - val_loss: 2.3628 - val_acc: 0.2531
Epoch 7/10
468/467 [==============================] - 37s 79ms/step - loss: 1.7925 - acc: 0.3633 - val_loss: 2.3095 - val_acc: 0.2538
Epoch 8/10
468/467 [==============================] - 38s 82ms/step - loss: 1.7699 - acc: 0.3716 - val_loss: 2.5055 - val_acc: 0.2236
Epoch 9/10
468/467 [==============================] - 36s 77ms/step - loss: 1.7486 - acc: 0.3775 - val_loss: 2.3271 - val_acc: 0.2594
Epoch 10/10
468/467 [==============================] - 39s 84ms/step - loss: 1.7443 - acc: 0.3814 - val_loss: 2.4001 - val_acc: 0.2523
Test loss: 2.40005418934444
Test accuracy: 0.25234192036473657
2019-01-05 21:25:10.926264
on validation data
11956/11956 [==============================] - 5s 381us/step
accuaracy 25.234192036473658
Total loss 240.005418934444
batchsize: 200
learnrate: 0.001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_31 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_32 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_35 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_14 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_20 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_21 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 42s 178ms/step - loss: 2.1531 - acc: 0.2400 - val_loss: 2.6483 - val_acc: 0.1654
Epoch 2/10
234/233 [==============================] - 40s 173ms/step - loss: 1.8964 - acc: 0.3214 - val_loss: 2.4463 - val_acc: 0.2492
Epoch 3/10
234/233 [==============================] - 43s 185ms/step - loss: 1.8196 - acc: 0.3531 - val_loss: 2.4202 - val_acc: 0.2400
Epoch 4/10
234/233 [==============================] - 42s 180ms/step - loss: 1.7812 - acc: 0.3673 - val_loss: 2.3803 - val_acc: 0.2553
Epoch 5/10
234/233 [==============================] - 42s 180ms/step - loss: 1.7449 - acc: 0.3816 - val_loss: 2.3013 - val_acc: 0.2489
Epoch 6/10
234/233 [==============================] - 42s 181ms/step - loss: 1.7221 - acc: 0.3856 - val_loss: 2.2854 - val_acc: 0.2806
Epoch 7/10
234/233 [==============================] - 44s 186ms/step - loss: 1.6964 - acc: 0.3973 - val_loss: 2.3349 - val_acc: 0.2777
Epoch 8/10
234/233 [==============================] - 43s 185ms/step - loss: 1.6729 - acc: 0.4045 - val_loss: 2.2288 - val_acc: 0.2733
Epoch 9/10
234/233 [==============================] - 44s 189ms/step - loss: 1.6642 - acc: 0.4080 - val_loss: 2.3493 - val_acc: 0.2719
Epoch 10/10
234/233 [==============================] - 44s 186ms/step - loss: 1.6352 - acc: 0.4190 - val_loss: 2.4711 - val_acc: 0.2763
Test loss: 2.4711427614416874
Test accuracy: 0.27634660421545665
2019-01-05 21:33:09.610544
on validation data
11956/11956 [==============================] - 4s 357us/step
accuaracy 27.634660421545664
Total loss 247.11427614416874
batchsize: 250
learnrate: 0.001
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_36 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_37 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_38 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_39 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_40 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_24 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_22 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_16 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_23 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_24 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 47s 249ms/step - loss: 2.3157 - acc: 0.1751 - val_loss: 2.5252 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 45s 242ms/step - loss: 2.2710 - acc: 0.1765 - val_loss: 2.5428 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 46s 245ms/step - loss: 2.2710 - acc: 0.1772 - val_loss: 2.5277 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 45s 241ms/step - loss: 2.2703 - acc: 0.1772 - val_loss: 2.5133 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 44s 235ms/step - loss: 2.2709 - acc: 0.1772 - val_loss: 2.5147 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 42s 222ms/step - loss: 2.2704 - acc: 0.1772 - val_loss: 2.5275 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 45s 242ms/step - loss: 2.2703 - acc: 0.1772 - val_loss: 2.5409 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 46s 244ms/step - loss: 2.2701 - acc: 0.1772 - val_loss: 2.5418 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 39s 209ms/step - loss: 2.2701 - acc: 0.1772 - val_loss: 2.5393 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 42s 223ms/step - loss: 2.2697 - acc: 0.1772 - val_loss: 2.5493 - val_acc: 0.1010
Test loss: 2.549282819860234
Test accuracy: 0.10103713617092712
2019-01-05 21:41:21.650440
on validation data
11956/11956 [==============================] - 5s 378us/step
accuaracy 10.103713617092712
Total loss 254.92828198602342
batchsize: 64
learnrate: 0.01
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_41 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_25 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_42 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_26 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_43 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_44 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_45 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_27 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_25 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_18 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_26 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_27 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 39s 53ms/step - loss: 13.2464 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2633 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2603 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-05 21:48:29.941059
on validation data
11956/11956 [==============================] - 5s 411us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 100
learnrate: 0.01
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_46 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_28 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_47 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_29 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_48 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_49 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_50 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_30 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_10 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_28 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_20 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_29 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_30 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
468/467 [==============================] - 37s 79ms/step - loss: 13.8362 - acc: 0.1400 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 2/10
468/467 [==============================] - 36s 78ms/step - loss: 13.8593 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 3/10
468/467 [==============================] - 36s 77ms/step - loss: 13.8593 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 4/10
468/467 [==============================] - 37s 79ms/step - loss: 13.8593 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 5/10
468/467 [==============================] - 37s 79ms/step - loss: 13.8588 - acc: 0.1402 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 6/10
468/467 [==============================] - 37s 79ms/step - loss: 13.8604 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 7/10
468/467 [==============================] - 36s 76ms/step - loss: 13.8598 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 8/10
468/467 [==============================] - 36s 76ms/step - loss: 13.8593 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 9/10
468/467 [==============================] - 37s 79ms/step - loss: 13.8619 - acc: 0.1400 - val_loss: 14.7592 - val_acc: 0.0843
Epoch 10/10
468/467 [==============================] - 38s 81ms/step - loss: 13.8598 - acc: 0.1401 - val_loss: 14.7592 - val_acc: 0.0843
Test loss: 14.759192473436128
Test accuracy: 0.08430913349195403
2019-01-05 21:55:30.429399
on validation data
11956/11956 [==============================] - 5s 409us/step
accuaracy 8.430913349195404
Total loss 1475.9192473436128
batchsize: 200
learnrate: 0.01
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_51 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_31 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_52 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_32 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_53 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_54 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_55 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_33 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_11 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_31 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_22 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_32 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_33 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
234/233 [==============================] - 44s 188ms/step - loss: 13.2175 - acc: 0.1767 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
234/233 [==============================] - 44s 188ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
234/233 [==============================] - 43s 186ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
234/233 [==============================] - 43s 186ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
234/233 [==============================] - 47s 200ms/step - loss: 13.2608 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
234/233 [==============================] - 46s 198ms/step - loss: 13.2599 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
234/233 [==============================] - 46s 198ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
234/233 [==============================] - 46s 197ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
234/233 [==============================] - 46s 196ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
234/233 [==============================] - 40s 171ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-05 22:03:52.163451
on validation data
11956/11956 [==============================] - 5s 422us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 250
learnrate: 0.01
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_56 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_34 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_57 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_35 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_58 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_59 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_60 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_36 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_12 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_34 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_24 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_35 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_36 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
187/186 [==============================] - 48s 258ms/step - loss: 13.2050 - acc: 0.1766 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
187/186 [==============================] - 44s 236ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
187/186 [==============================] - 42s 223ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
187/186 [==============================] - 45s 239ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
187/186 [==============================] - 43s 231ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
187/186 [==============================] - 45s 243ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
187/186 [==============================] - 43s 231ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
187/186 [==============================] - 44s 234ms/step - loss: 13.2614 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
187/186 [==============================] - 44s 235ms/step - loss: 13.2613 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
187/186 [==============================] - 46s 246ms/step - loss: 13.2615 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-05 22:12:10.021530
on validation data
11956/11956 [==============================] - 5s 411us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 64
learnrate: 0.1
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_61 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_37 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_62 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_38 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_63 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_64 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_65 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_39 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_13 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_37 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_26 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_38 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_39 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
731/730 [==============================] - 38s 52ms/step - loss: 13.2478 - acc: 0.1769 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 2/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 3/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 4/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2595 - acc: 0.1774 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 5/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2610 - acc: 0.1773 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 6/10
731/730 [==============================] - 36s 49ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 7/10
731/730 [==============================] - 37s 50ms/step - loss: 13.2626 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 8/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 9/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2618 - acc: 0.1772 - val_loss: 14.4896 - val_acc: 0.1010
Epoch 10/10
731/730 [==============================] - 37s 51ms/step - loss: 13.2633 - acc: 0.1771 - val_loss: 14.4896 - val_acc: 0.1010
Test loss: 14.489569019178516
Test accuracy: 0.10103713617092712
2019-01-05 22:19:12.901713
on validation data
11956/11956 [==============================] - 5s 384us/step
accuaracy 10.103713617092712
Total loss 1448.9569019178516
batchsize: 100
learnrate: 0.1
filters: 96
maske: 11
X_train shape: (46740, 227, 227, 3)
X_test shape: (11956, 227, 227, 3)
46740 train samples
11956 test samples
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_66 (Conv2D)           (None, 55, 55, 96)        34944     
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_67 (Conv2D)           (None, 23, 23, 256)       614656    
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 11, 11, 256)       0         
_________________________________________________________________
conv2d_68 (Conv2D)           (None, 9, 9, 384)         885120    
_________________________________________________________________
conv2d_69 (Conv2D)           (None, 7, 7, 384)         1327488   
_________________________________________________________________
conv2d_70 (Conv2D)           (None, 5, 5, 256)         884992    
_________________________________________________________________
max_pooling2d_42 (MaxPooling (None, 2, 2, 256)         0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 2, 2, 256)         0         
_________________________________________________________________
flatten_14 (Flatten)         (None, 1024)              0         
_________________________________________________________________
dense_40 (Dense)             (None, 9216)              9446400   
_________________________________________________________________
dropout_28 (Dropout)         (None, 9216)              0         
_________________________________________________________________
dense_41 (Dense)             (None, 4096)              37752832  
_________________________________________________________________
dense_42 (Dense)             (None, 11)                45067     
=================================================================
Total params: 50,991,499
Trainable params: 50,991,499
Non-trainable params: 0
_________________________________________________________________
Traceback (most recent call last):
  File "repetition.py", line 351, in <module>
    run(100, 0.1, 96, 11)
  File "repetition.py", line 258, in run
    datagen_train.fit(X_train)
  File "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image.py", line 1363, in fit
    x = np.copy(x)
  File "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py", line 733, in copy
    return array(a, order=order, copy=True)
MemoryError